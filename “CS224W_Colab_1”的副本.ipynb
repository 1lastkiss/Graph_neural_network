{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1lastkiss/Graph_neural_network/blob/main/%E2%80%9CCS224W_Colab_1%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this Colab, we will write a full pipeline for **learning node embeddings**.\n",
        "We will go through the following 3 steps.\n",
        "\n",
        "To start, we will load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). We will explore multiple graph statistics for that graph.\n",
        "\n",
        "We will then work together to transform the graph structure into a PyTorch tensor, so that we can perform machine learning over the graph.\n",
        "\n",
        "Finally, we will finish the first learning algorithm on graphs: a node embedding model. For simplicity, our model here is simpler than DeepWalk / node2vec algorithms taught in the lecture. But it's still rewarding and challenging, as we will write it from scratch via PyTorch.\n",
        "\n",
        "Now let's get started!\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells**, so that the intermediate variables / packages will carry over to the next cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1 Graph Basics\n",
        "To start, we will load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). We will explore multiple graph statistics for that graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDkpByYYfSzb"
      },
      "source": [
        "## Setup\n",
        "We will heavily use NetworkX in this Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWPkJjPAfVNW"
      },
      "source": [
        "import networkx as nx"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUnYT5qUZYh"
      },
      "source": [
        "## Zachary's karate club network\n",
        "\n",
        "The [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) is a graph which describes a social network of 34 members of a karate club and documents links between members who interacted outside the club."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIETqEfrfy5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fab2cae-5cbc-4c37-ac9b-4ceaf1a5ec1c"
      },
      "source": [
        "G = nx.karate_club_graph()\n",
        "\n",
        "# G is an undirected graph\n",
        "type(G)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "networkx.classes.graph.Graph"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDvf3nm-ors4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "74868de5-260b-4d19-d666-0f4bba8102bf"
      },
      "source": [
        "# Visualize the graph\n",
        "nx.draw(G, with_labels = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX25Y1CrYmgN"
      },
      "source": [
        "## Question 1: What is the average degree of the karate club network? (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUhES1VYo3tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dc8f1d-2cf5-4d82-b536-1682f018cb5b"
      },
      "source": [
        "def average_degree(num_edges, num_nodes):\n",
        "  # TODO: Implement this function that takes number of edges\n",
        "  # and number of nodes, and returns the average node degree of \n",
        "  # the graph. Round the result to nearest integer (for example \n",
        "  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4)\n",
        "\n",
        "  avg_degree = 0\n",
        "  node_num = G.number_of_nodes()\n",
        "  edge_num = G.number_of_edges()\n",
        "  avg_degree = edge_num * 2 / node_num\n",
        " \n",
        "  return round(avg_degree)\n",
        "\n",
        "num_edges = G.number_of_edges()\n",
        "num_nodes = G.number_of_nodes()\n",
        "avg_degree = average_degree(num_edges, num_nodes)\n",
        "print(\"Average degree of karate club network is {}\".format(avg_degree))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average degree of karate club network is 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk02fD4vYmZI"
      },
      "source": [
        "## Question 2: What is the average clustering coefficient of the karate club network? (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k15XKEto1aYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125fea53-5116-456d-8de4-5a58fff11b6f"
      },
      "source": [
        "def average_clustering_coefficient(G):\n",
        "  # TODO: Implement this function that takes a nx.Graph\n",
        "  # and returns the average clustering coefficient. Round \n",
        "  # the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "\n",
        "  avg_cluster_coef = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Please use the appropriate NetworkX clustering function\n",
        "  avg_cluster_coef = nx.average_clustering(G)\n",
        "  avg_cluster_coef = round(avg_cluster_coef, 2)\n",
        "  #########################################\n",
        "\n",
        "  return avg_cluster_coef\n",
        "\n",
        "avg_cluster_coef = average_clustering_coefficient(G)\n",
        "print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average clustering coefficient of karate club network is 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghQ-AhXYmP4"
      },
      "source": [
        "## Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)\n",
        "\n",
        "Page Rank measures importance of nodes in a graph using the link structure of the web. A “vote” from an important page is worth more. Specifically, if  a page $i$ with importance $r_i$ has $d_i$ out-links, then each link gets $\\frac{r_i}{d_i}$ votes. Thus, the importance of a Page $j$, represented as $r_j$ is the sum of the votes on its in links. \n",
        "$$r_j = \\sum_{i \\rightarrow j} \\frac{r_i}{d_i}$$, where $d_i$ is the out degree of node $i$.\n",
        "\n",
        "The PageRank algorithm (used by Google) outputs a probability distribution which represent the likelihood of a random surfer clicking on links will arrive at any particular page. At each time step, the random surfer has two options\n",
        "- With prob. $\\beta$, follow a link at random \n",
        "- With prob. $1- \\beta$, jump to a random page\n",
        "\n",
        "Thus, the importance of a particular page is calculated with the following PageRank equation:\n",
        " $$r_j = \\sum_{i \\rightarrow j} \\beta \\frac{r_i}{d_i} + (1 - \\beta) \\frac{1}{N}$$\n",
        "\n",
        "Please complete the code block by implementing the above PageRank equation for node 0.\n",
        "\n",
        "Note - You can refer to more information from the slides here - http://snap.stanford.edu/class/cs224w-2020/slides/04-pagerank.pdf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOGdWjNc6O7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b8d8ba-e958-448a-ef6e-291ff4951eb7"
      },
      "source": [
        "def one_iter_pagerank(G, beta, r0, node_id):\n",
        "  # TODO: Implement this function that takes a nx.Graph, beta, r0 and node id.\n",
        "  # The return value r1 is one interation PageRank value for the input node.\n",
        "  # Please round r1 to 2 decimal places.\n",
        "\n",
        "  r1 = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: You should not use nx.pagerank\n",
        "  node_num = G.number_of_nodes()\n",
        "  degree = G.degree[node_id]\n",
        "  # print(degree)\n",
        "  #########################################\n",
        "  for neighbor in G.neighbors(node_id):\n",
        "    r1 += beta * (r0 / G.degree[neighbor])\n",
        "  r1 += (1 - beta) / node_num \n",
        "  r1 = round(r1, 2)\n",
        "  return r1\n",
        "\n",
        "beta = 0.8\n",
        "r0 = 1 / G.number_of_nodes()\n",
        "node = 0\n",
        "r1 = one_iter_pagerank(G, beta, r0, node)\n",
        "print(\"The PageRank value for node 0 after one iteration is {}\".format(r1))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The PageRank value for node 0 after one iteration is 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icTcOULeYmIu"
      },
      "source": [
        "## Question 4: What is the (raw) closeness centrality for the karate club network node 5? (5 Points)\n",
        "\n",
        "The equation for closeness centrality is $c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbCsq_tl-3ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9ac552-574c-4c43-a172-84be385f9d03"
      },
      "source": [
        "def closeness_centrality(G, node=5):\n",
        "  # TODO: Implement the function that calculates closeness centrality \n",
        "  # for a node in karate club network. G is the input karate club \n",
        "  # network and node is the node id in the graph. Please round the \n",
        "  # closeness centrality result to 2 decimal places.\n",
        "\n",
        "  closeness = 0\n",
        "\n",
        "  ## Note:\n",
        "  ## 1: You can use networkx closeness centrality function.\n",
        "  ## 2: Notice that networkx closeness centrality returns the normalized \n",
        "  ## closeness directly, which is different from the raw (unnormalized) \n",
        "  ## one that we learned in the lecture.\n",
        "  length =0 \n",
        "  for path in list(nx.single_source_shortest_path_length(G, node).values()):\n",
        "    length += path\n",
        "  #########################################\n",
        "  closeness = 1 / length\n",
        "  closeness = round(closeness, 2)\n",
        "  return closeness\n",
        "\n",
        "node = 5\n",
        "closeness = closeness_centrality(G, node=node)\n",
        "print(\"The node 5 has closeness centrality {}\".format(closeness))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The node 5 has closeness centrality 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MxvowibYl4x"
      },
      "source": [
        "# 2 Graph to Tensor\n",
        "We will then work together to transform the graph $G$ into a PyTorch tensor, so that we can perform machine learning over the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDA8PosrA-9V"
      },
      "source": [
        "## Setup\n",
        "Check if PyTorch is properly installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntuPVat_BAf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22af7090-dff5-429a-9e15-fcb8d130d041"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fko_2wSKYlun"
      },
      "source": [
        "## PyTorch tensor basics\n",
        "\n",
        "We can generate PyTorch tensor with all zeros, ones or random values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ySw3m-A9qF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f9c5b9-dc26-4436-e2e6-d99e20333872"
      },
      "source": [
        "# Generate 3 x 4 tensor with all ones\n",
        "ones = torch.ones(3, 4)\n",
        "print(ones)\n",
        "\n",
        "# Generate 3 x 4 tensor with all zeros\n",
        "zeros = torch.zeros(3, 4)\n",
        "print(zeros)\n",
        "\n",
        "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "print(random_tensor)\n",
        "\n",
        "# Get the shape of the tensor\n",
        "print(ones.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[0.6868, 0.7783, 0.8719, 0.4771],\n",
            "        [0.2022, 0.3985, 0.0763, 0.8199],\n",
            "        [0.0270, 0.1828, 0.0049, 0.1217]])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mp66eHBxWC"
      },
      "source": [
        "PyTorch tensor contains elements for a single data type, the `dtype`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQiOvKJJBwq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72ba942-1f2c-49b6-b173-460f473375a8"
      },
      "source": [
        "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
        "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
        "print(zeros.dtype)\n",
        "\n",
        "# Change the tensor dtype to 64-bit integer\n",
        "zeros = zeros.type(torch.long)\n",
        "print(zeros.dtype)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EfegIRDkk2"
      },
      "source": [
        "## Question 5: Get the edge list of the karate club network and transform it into `torch.LongTensor`. What is the `torch.sum` value of `pos_edge_index` tensor? (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEtVxMFID3ZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad6145c-ed0f-4ba6-e94a-038c9ec9f629"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def graph_to_edge_list(G):\n",
        "  # TODO: Implement the function that returns the edge list of\n",
        "  # an nx.Graph. The returned edge_list should be a list of tuples\n",
        "  # where each tuple is a tuple representing an edge connected \n",
        "  # by two nodes.\n",
        "\n",
        "  edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  edge_list = list(G.edges())\n",
        "  \n",
        "  #########################################\n",
        "\n",
        "  return edge_list\n",
        "\n",
        "def edge_list_to_tensor(edge_list):\n",
        "  # TODO: Implement the function that transforms the edge_list to\n",
        "  # tensor. The input edge_list is a list of tuples and the resulting\n",
        "  # tensor should have the shape [2 x len(edge_list)].\n",
        "\n",
        "  edge_index = torch.tensor([])\n",
        "\n",
        "  ############# Your code here ############\n",
        "  edge_index = torch.tensor(np.array(edge_list), dtype = torch.long)\n",
        "  # print(edge_index)\n",
        "  print(edge_index.shape)\n",
        "  edge_index = edge_index.T\n",
        "  print(edge_index.shape)\n",
        "  \n",
        "  #########################################\n",
        "\n",
        "  return edge_index\n",
        "\n",
        "pos_edge_list = graph_to_edge_list(G)\n",
        "pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
        "print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n",
        "print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))\n",
        "print(type(G.edges()))\n",
        "print(set(G.edges()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([78, 2])\n",
            "torch.Size([2, 78])\n",
            "The pos_edge_index tensor has shape torch.Size([2, 78])\n",
            "The pos_edge_index tensor has sum value 2535\n",
            "<class 'networkx.classes.reportviews.EdgeView'>\n",
            "{(13, 33), (3, 13), (5, 10), (29, 32), (23, 25), (0, 5), (15, 32), (2, 32), (23, 27), (0, 7), (14, 33), (1, 17), (8, 32), (20, 33), (31, 33), (23, 29), (1, 19), (2, 27), (0, 2), (5, 16), (22, 32), (1, 3), (1, 21), (1, 30), (25, 31), (3, 12), (23, 33), (27, 33), (2, 13), (24, 25), (29, 33), (14, 32), (1, 7), (3, 7), (4, 6), (20, 32), (18, 32), (31, 32), (0, 11), (2, 8), (8, 33), (19, 33), (30, 33), (26, 29), (5, 6), (1, 2), (0, 4), (0, 13), (0, 31), (2, 28), (4, 10), (0, 6), (2, 3), (1, 13), (28, 31), (24, 27), (15, 33), (26, 33), (0, 8), (0, 17), (28, 33), (8, 30), (32, 33), (0, 1), (0, 10), (2, 7), (0, 19), (30, 32), (6, 16), (24, 31), (18, 33), (0, 3), (22, 33), (23, 32), (0, 12), (2, 9), (0, 21), (9, 33)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBL-ZmdHWqIu"
      },
      "source": [
        "## Question 6: Please implement following function that samples negative edges. Then answer which edges (edge_1 to edge_5) are the negative edges in the karate club network? (10 Points)\n",
        "\n",
        "\"Negative\" edges refer to the edges/links that do not exist in the graph. The term \"negative\" is borrowed from \"negative sampling\" in link prediction. It has nothing to do with the edge weights.\n",
        "\n",
        "For example, given an edge (src, dst), you should check that neither (src, dst) nor (dst, src) are edges in the Graph. If these hold true, then it is a negative edge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N8VT1f8-IJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728ba38e-93de-4a3d-9bf9-ee2bda11e0f5"
      },
      "source": [
        "import random\n",
        "\n",
        "def sample_negative_edges(G, num_neg_samples):\n",
        "  # TODO: Implement the function that returns a list of negative edges.\n",
        "  # The number of sampled negative edges is num_neg_samples. You do not\n",
        "  # need to consider the corner case when the number of possible negative edges\n",
        "  # is less than num_neg_samples. It should be ok as long as your implementation \n",
        "  # works on the karate club network. In this implementation, self loops should \n",
        "  # not be considered as either a positive or negative edge. Also, notice that \n",
        "  # the karate club network is an undirected graph, if (0, 1) is a positive \n",
        "  # edge, do you think (1, 0) can be a negative one?\n",
        "\n",
        "  neg_edge_list = []\n",
        "\n",
        "  node_list = list(G.nodes())\n",
        "  pos_set = set(G.edges())\n",
        "  visited_set = set() \n",
        "  \n",
        "  ############# Your code here ############\n",
        "  random.shuffle(node_list)\n",
        "    \n",
        "  for n_i in node_list:\n",
        "      for n_j in node_list:\n",
        "          if n_i == n_j \\\n",
        "          or (n_i,n_j) in pos_set or (n_j,n_i) in pos_set \\\n",
        "          or (n_i,n_j) in visited_set or (n_j, n_i) is visited_set:\n",
        "              continue\n",
        "              \n",
        "          neg_edge_list.append((n_i,n_j))\n",
        "          visited_set.add((n_i,n_j))\n",
        "          visited_set.add((n_j,n_i))\n",
        "          if len(neg_edge_list) == num_neg_samples:\n",
        "              return neg_edge_list\n",
        "\n",
        "# Sample 78 negative edges\n",
        "neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
        "\n",
        "\n",
        "# Transform the negative edge list to tensor\n",
        "neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
        "print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
        "print(neg_edge_index)\n",
        "# Which of following edges can be negative ones?\n",
        "edge_1 = (7, 1)\n",
        "edge_2 = (1, 33)\n",
        "edge_3 = (33, 22)\n",
        "edge_4 = (0, 4)\n",
        "edge_5 = (4, 2)\n",
        "\n",
        "############# Your code here ############\n",
        "## Note:\n",
        "## 1: For each of the 5 edges, print whether it can be negative edge\n",
        "def is_neg_edge(edge, G):\n",
        "  if edge in list(G.edges()) or (edge[1], edge[0]) in list(G.edges()):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "#########################################\n",
        "print(is_neg_edge(edge_1, G))\n",
        "print(is_neg_edge(edge_2, G))\n",
        "print(is_neg_edge(edge_3, G))\n",
        "print(is_neg_edge(edge_4, G))\n",
        "print(is_neg_edge(edge_5, G))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([78, 2])\n",
            "torch.Size([2, 78])\n",
            "The neg_edge_index tensor has shape torch.Size([2, 78])\n",
            "tensor([[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,  9,  9,  9,  9,  9,\n",
            "          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
            "          9,  9,  9,  9,  9,  9,  9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "         14, 14, 14, 14, 14, 14],\n",
            "        [ 9, 14, 30, 13, 21, 10,  6, 27, 24, 22, 15, 17,  0, 11, 20, 19,  2, 25,\n",
            "         23,  3, 26, 12, 29,  5,  8, 28, 31,  1,  7, 16,  4, 14, 30, 13, 21, 10,\n",
            "          6, 27, 24, 22, 15, 17,  0, 11, 20, 19, 25, 23,  3, 26, 12, 29,  5,  8,\n",
            "         28, 31,  1,  7, 32, 16,  4, 30, 13, 21, 10,  6, 27, 24, 22, 15, 17,  0,\n",
            "         11, 20, 19,  2, 25, 23]])\n",
            "False\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9Q-a-9qGsw"
      },
      "source": [
        "# 3 Node Emebedding Learning\n",
        "\n",
        "Finally, we will finish the first learning algorithm on graphs: a node embedding model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDBxRQcZ_dUH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnqn9H6s_ehX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6d728e-a38e-4e68-be0b-a7a16b147177"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gomAf8vxq0R"
      },
      "source": [
        "To write our own node embedding learning methods, we'll heavily use the [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module in PyTorch. Let's see how to use `nn.Embedding`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRiWGuLAx5yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d30778-b826-4a68-e87c-06119885907d"
      },
      "source": [
        "# Initialize an embedding layer\n",
        "# Suppose we want to have embedding for 4 items (e.g., nodes)\n",
        "# Each item is represented with 8 dimensional vector\n",
        "\n",
        "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
        "print('Sample embedding layer: {}'.format(emb_sample))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample embedding layer: Embedding(4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS9qQfeujEVh"
      },
      "source": [
        "We can select items from the embedding matrix, by using Tensor indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AGIfP4QEDr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbdf20c-8455-4f55-8267-0dfdfb4147ba"
      },
      "source": [
        "# Select an embedding in emb_sample\n",
        "id = torch.LongTensor([1])\n",
        "print(emb_sample(id))\n",
        "\n",
        "# Select multiple embeddings\n",
        "ids = torch.LongTensor([1, 3])\n",
        "print(emb_sample(ids))\n",
        "\n",
        "# Get the shape of the embedding weight matrix\n",
        "shape = emb_sample.weight.data.shape\n",
        "print(shape)\n",
        "\n",
        "# Overwrite the weight to tensor with all ones\n",
        "emb_sample.weight.data = torch.ones(shape)\n",
        "\n",
        "# Let's check if the emb is indeed initilized\n",
        "ids = torch.LongTensor([0, 3])\n",
        "print(emb_sample(ids))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4947,  0.4902,  1.4366, -0.5891,  0.8100, -0.1045,  2.3745, -1.3568]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "tensor([[-0.4947,  0.4902,  1.4366, -0.5891,  0.8100, -0.1045,  2.3745, -1.3568],\n",
            "        [-0.2554,  2.1678, -0.6932, -1.4249,  1.2815, -1.5724, -0.6991, -0.0821]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([4, 8])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MjBuDKaKIsM"
      },
      "source": [
        "Now, it's your time to create node embedding matrix for the graph we have!\n",
        "- We want to have **16 dimensional** vector for each node in the karate club network.\n",
        "- We want to initalize the matrix under **uniform distribution**, in the range of $[0, 1)$. We suggest you using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMszSwRPKGn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f904a303-386d-45a8-ab27-94af503295ad"
      },
      "source": [
        "# Please do not change / reset the random seed\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def create_node_emb(num_node=34, embedding_dim=16):\n",
        "  # TODO: Implement this function that will create the node embedding matrix.\n",
        "  # A torch.nn.Embedding layer will be returned. You do not need to change \n",
        "  # the values of num_node and embedding_dim. The weight matrix of returned \n",
        "  # layer should be initialized under uniform distribution. \n",
        "\n",
        "  emb = None\n",
        "  emb = nn.Embedding(num_embeddings = num_node, embedding_dim = embedding_dim) \n",
        "  shape = emb.weight.data.shape\n",
        "  emb.weight.data = torch.rand(shape)\n",
        "  ############# Your code here ############\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return emb\n",
        "\n",
        "emb = create_node_emb()\n",
        "ids = torch.LongTensor([0, 1, 3])\n",
        "\n",
        "# Print the embedding layer\n",
        "print(\"Embedding: {}\".format(emb))\n",
        "\n",
        "# An example that gets the embeddings for node 0 and 3\n",
        "print(emb(ids))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding: Embedding(34, 16)\n",
            "tensor([[0.2114, 0.7335, 0.1433, 0.9647, 0.2933, 0.7951, 0.5170, 0.2801, 0.8339,\n",
            "         0.1185, 0.2355, 0.5599, 0.8966, 0.2858, 0.1955, 0.1808],\n",
            "        [0.2796, 0.3273, 0.3835, 0.2156, 0.6563, 0.5041, 0.1733, 0.2145, 0.6059,\n",
            "         0.4929, 0.8539, 0.4242, 0.0949, 0.1302, 0.3532, 0.3893],\n",
            "        [0.7486, 0.6546, 0.3843, 0.9820, 0.6012, 0.3710, 0.4929, 0.9915, 0.8358,\n",
            "         0.4629, 0.9902, 0.7196, 0.2338, 0.0450, 0.7906, 0.9689]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QfoANibTzyh"
      },
      "source": [
        "## Visualize the initial node embeddings\n",
        "One good way to understand an embedding matrix, is to visualize it in a 2D space.\n",
        "Here, we have implemented an embedding visualization function for you.\n",
        "We first do PCA to reduce the dimensionality of embeddings to a 2D space.\n",
        "Then we visualize each point, colored by the community it belongs to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LCoIkarhfYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b5a67259-6e8b-42f4-b765-c629f72dca71"
      },
      "source": [
        "def visualize_emb(emb):\n",
        "  X = emb.weight.data.numpy()\n",
        "  pca = PCA(n_components=2)\n",
        "  components = pca.fit_transform(X)\n",
        "  # print(components.shape)\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  club1_x = []\n",
        "  club1_y = []\n",
        "  club2_x = []\n",
        "  club2_y = []\n",
        "  for node in G.nodes(data=True):\n",
        "    if node[1]['club'] == 'Mr. Hi':\n",
        "      club1_x.append(components[node[0]][0])\n",
        "      club1_y.append(components[node[0]][1])\n",
        "    else:\n",
        "      club2_x.append(components[node[0]][0])\n",
        "      club2_y.append(components[node[0]][1])\n",
        "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
        "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the initial random embeddding\n",
        "visualize_emb(emb)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQIyuEz9ANb2"
      },
      "source": [
        "## Question 7: Training the embedding! What is the best performance you can get? Please report both the best loss and accuracy on Gradescope. (20 Points)\n",
        "\n",
        "We want to optimize our embeddings for the task of classifying edges as positive or negative. Given an edge and the embeddings for each node, the dot product of the embeddings, followed by a sigmoid, should give us the likelihood of that edge being either positive (output of sigmoid > 0.5) or negative (output of sigmoid < 0.5).\n",
        "\n",
        "Note that we're using the functions you wrote in the previous questions, _as well as the variables initialized in previous cells_. If you're running into issues, make sure your answers to questions 1-6 are correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDeQTNNxqH0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2197df5-4936-4889-dd90-776e3026ee28"
      },
      "source": [
        "from torch.optim import SGD\n",
        "import torch.nn as nn\n",
        "\n",
        "def accuracy(pred, label):\n",
        "  # TODO: Implement the accuracy function. This function takes the \n",
        "  # pred tensor (the resulting tensor after sigmoid) and the label \n",
        "  # tensor (torch.LongTensor). Predicted value greater than 0.5 will \n",
        "  # be classified as label 1. Else it will be classified as label 0.\n",
        "  # The returned accuracy should be rounded to 4 decimal places. \n",
        "  # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
        "\n",
        "  accu = 0.0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  pred = [1 if item > 0.5 else 0 for item in pred]\n",
        "  num_match = (np.array(pred) == np.array(label)).sum()\n",
        "  accu = num_match / len(label)\n",
        "  accu = round(accu, 4)\n",
        "  \n",
        "  #########################################\n",
        "\n",
        "  return accu\n",
        "\n",
        "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
        "  # TODO: Train the embedding layer here. You can also change epochs and \n",
        "  # learning rate. In general, you need to implement: \n",
        "  # (1) Get the embeddings of the nodes in train_edge\n",
        "  # (2) Dot product the embeddings between each node pair\n",
        "  # (3) Feed the dot product result into sigmoid\n",
        "  # (4) Feed the sigmoid output into the loss_fn\n",
        "  # (5) Print both loss and accuracy of each epoch \n",
        "  # (6) Update the embeddings using the loss and optimizer \n",
        "  # (as a sanity check, the loss should decrease during training)\n",
        "\n",
        "  epochs = 500\n",
        "  learning_rate = 0.1\n",
        "\n",
        "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    ############# Your code here ############\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # (1)Get the embeddings of the nodes in train_edge\n",
        "    emb_v = emb(train_edge[0])\n",
        "    emb_u = emb(train_edge[1])\n",
        "\n",
        "    # (2) Dot product the embeddings between each node pair\n",
        "    dot_product = torch.sum(emb_u * emb_v, dim = -1)\n",
        "\n",
        "    # (3) Feed the dot product result into sigmoid\n",
        "    sig = sigmoid(dot_product)\n",
        "\n",
        "    # (4) 计算损失函数\n",
        "    loss = loss_fn(sig, train_label)\n",
        "\n",
        "    \n",
        "\n",
        "    # (5) 打印每个epoch的loss 和 accuracy\n",
        "    print(f\"Loss in {i} epoch is {loss}\")\n",
        "    print(f\"accuracy in {i} epoch is {accuracy(sig, train_label)}\")\n",
        "    print() # 空一行\n",
        "\n",
        "    # gradient discent\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #########################################\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "print(pos_edge_index.shape)\n",
        "\n",
        "# Generate the positive and negative labels\n",
        "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "# Concat positive and negative labels into one tensor\n",
        "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "print(train_label)\n",
        "# Concat positive and negative edges into one tensor\n",
        "# Since the network is very small, we do not split the edges into val/test sets\n",
        "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "print(train_edge.shape)\n",
        "print(train_edge[0])\n",
        "print(train_edge[1])\n",
        "print(emb(train_edge[0]))\n",
        "train(emb, loss_fn, sigmoid, train_label, train_edge)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 78])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "torch.Size([2, 156])\n",
            "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  4,\n",
            "         4,  5,  5,  5,  6,  8,  8,  8,  9, 13, 14, 14, 15, 15, 18, 18, 19, 20,\n",
            "        20, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 26, 26, 27, 28, 28, 29,\n",
            "        29, 30, 30, 31, 31, 32, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "        18,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
            "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])\n",
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  2,  3,\n",
            "         7, 13, 17, 19, 21, 30,  3,  7,  8,  9, 13, 27, 28, 32,  7, 12, 13,  6,\n",
            "        10,  6, 10, 16, 16, 30, 32, 33, 33, 33, 32, 33, 32, 33, 32, 33, 33, 32,\n",
            "        33, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 31, 29, 33, 33, 31, 33, 32,\n",
            "        33, 32, 33, 32, 33, 33,  9, 14, 30, 13, 21, 10,  6, 27, 24, 22, 15, 17,\n",
            "         0, 11, 20, 19,  2, 25, 23,  3, 26, 12, 29,  5,  8, 28, 31,  1,  7, 16,\n",
            "         4, 14, 30, 13, 21, 10,  6, 27, 24, 22, 15, 17,  0, 11, 20, 19, 25, 23,\n",
            "         3, 26, 12, 29,  5,  8, 28, 31,  1,  7, 32, 16,  4, 30, 13, 21, 10,  6,\n",
            "        27, 24, 22, 15, 17,  0, 11, 20, 19,  2, 25, 23])\n",
            "tensor([[0.2114, 0.7335, 0.1433,  ..., 0.2858, 0.1955, 0.1808],\n",
            "        [0.2114, 0.7335, 0.1433,  ..., 0.2858, 0.1955, 0.1808],\n",
            "        [0.2114, 0.7335, 0.1433,  ..., 0.2858, 0.1955, 0.1808],\n",
            "        ...,\n",
            "        [0.4196, 0.7000, 0.1163,  ..., 0.5949, 0.4427, 0.5351],\n",
            "        [0.4196, 0.7000, 0.1163,  ..., 0.5949, 0.4427, 0.5351],\n",
            "        [0.4196, 0.7000, 0.1163,  ..., 0.5949, 0.4427, 0.5351]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Loss in 0 epoch is 1.697098970413208\n",
            "accuracy in 0 epoch is 0.5\n",
            "\n",
            "Loss in 1 epoch is 1.6601284742355347\n",
            "accuracy in 1 epoch is 0.5\n",
            "\n",
            "Loss in 2 epoch is 1.590834617614746\n",
            "accuracy in 2 epoch is 0.5\n",
            "\n",
            "Loss in 3 epoch is 1.4942642450332642\n",
            "accuracy in 3 epoch is 0.5\n",
            "\n",
            "Loss in 4 epoch is 1.3758128881454468\n",
            "accuracy in 4 epoch is 0.5\n",
            "\n",
            "Loss in 5 epoch is 1.2412421703338623\n",
            "accuracy in 5 epoch is 0.5\n",
            "\n",
            "Loss in 6 epoch is 1.0967248678207397\n",
            "accuracy in 6 epoch is 0.5\n",
            "\n",
            "Loss in 7 epoch is 0.9488558769226074\n",
            "accuracy in 7 epoch is 0.5\n",
            "\n",
            "Loss in 8 epoch is 0.8045186996459961\n",
            "accuracy in 8 epoch is 0.5\n",
            "\n",
            "Loss in 9 epoch is 0.6704388856887817\n",
            "accuracy in 9 epoch is 0.5321\n",
            "\n",
            "Loss in 10 epoch is 0.5523146390914917\n",
            "accuracy in 10 epoch is 0.5962\n",
            "\n",
            "Loss in 11 epoch is 0.4537442624568939\n",
            "accuracy in 11 epoch is 0.7564\n",
            "\n",
            "Loss in 12 epoch is 0.37558889389038086\n",
            "accuracy in 12 epoch is 0.8269\n",
            "\n",
            "Loss in 13 epoch is 0.3162892162799835\n",
            "accuracy in 13 epoch is 0.859\n",
            "\n",
            "Loss in 14 epoch is 0.2729104459285736\n",
            "accuracy in 14 epoch is 0.8718\n",
            "\n",
            "Loss in 15 epoch is 0.24220862984657288\n",
            "accuracy in 15 epoch is 0.891\n",
            "\n",
            "Loss in 16 epoch is 0.2212575078010559\n",
            "accuracy in 16 epoch is 0.9167\n",
            "\n",
            "Loss in 17 epoch is 0.20765116810798645\n",
            "accuracy in 17 epoch is 0.9295\n",
            "\n",
            "Loss in 18 epoch is 0.19948424398899078\n",
            "accuracy in 18 epoch is 0.9423\n",
            "\n",
            "Loss in 19 epoch is 0.19526731967926025\n",
            "accuracy in 19 epoch is 0.9487\n",
            "\n",
            "Loss in 20 epoch is 0.19384223222732544\n",
            "accuracy in 20 epoch is 0.9487\n",
            "\n",
            "Loss in 21 epoch is 0.1943131536245346\n",
            "accuracy in 21 epoch is 0.9423\n",
            "\n",
            "Loss in 22 epoch is 0.19599223136901855\n",
            "accuracy in 22 epoch is 0.9423\n",
            "\n",
            "Loss in 23 epoch is 0.19835686683654785\n",
            "accuracy in 23 epoch is 0.9423\n",
            "\n",
            "Loss in 24 epoch is 0.20101569592952728\n",
            "accuracy in 24 epoch is 0.9423\n",
            "\n",
            "Loss in 25 epoch is 0.20368176698684692\n",
            "accuracy in 25 epoch is 0.9423\n",
            "\n",
            "Loss in 26 epoch is 0.20615077018737793\n",
            "accuracy in 26 epoch is 0.9423\n",
            "\n",
            "Loss in 27 epoch is 0.20828337967395782\n",
            "accuracy in 27 epoch is 0.9423\n",
            "\n",
            "Loss in 28 epoch is 0.209990993142128\n",
            "accuracy in 28 epoch is 0.9423\n",
            "\n",
            "Loss in 29 epoch is 0.21122391521930695\n",
            "accuracy in 29 epoch is 0.9423\n",
            "\n",
            "Loss in 30 epoch is 0.2119620144367218\n",
            "accuracy in 30 epoch is 0.9423\n",
            "\n",
            "Loss in 31 epoch is 0.2122071534395218\n",
            "accuracy in 31 epoch is 0.9423\n",
            "\n",
            "Loss in 32 epoch is 0.21197722852230072\n",
            "accuracy in 32 epoch is 0.9423\n",
            "\n",
            "Loss in 33 epoch is 0.21130146086215973\n",
            "accuracy in 33 epoch is 0.9423\n",
            "\n",
            "Loss in 34 epoch is 0.2102167159318924\n",
            "accuracy in 34 epoch is 0.9423\n",
            "\n",
            "Loss in 35 epoch is 0.20876480638980865\n",
            "accuracy in 35 epoch is 0.9423\n",
            "\n",
            "Loss in 36 epoch is 0.20699019730091095\n",
            "accuracy in 36 epoch is 0.9423\n",
            "\n",
            "Loss in 37 epoch is 0.20493830740451813\n",
            "accuracy in 37 epoch is 0.9423\n",
            "\n",
            "Loss in 38 epoch is 0.20265428721904755\n",
            "accuracy in 38 epoch is 0.9423\n",
            "\n",
            "Loss in 39 epoch is 0.20018203556537628\n",
            "accuracy in 39 epoch is 0.9423\n",
            "\n",
            "Loss in 40 epoch is 0.19756348431110382\n",
            "accuracy in 40 epoch is 0.9423\n",
            "\n",
            "Loss in 41 epoch is 0.19483809173107147\n",
            "accuracy in 41 epoch is 0.9423\n",
            "\n",
            "Loss in 42 epoch is 0.19204245507717133\n",
            "accuracy in 42 epoch is 0.9423\n",
            "\n",
            "Loss in 43 epoch is 0.18920990824699402\n",
            "accuracy in 43 epoch is 0.9423\n",
            "\n",
            "Loss in 44 epoch is 0.18637070059776306\n",
            "accuracy in 44 epoch is 0.9423\n",
            "\n",
            "Loss in 45 epoch is 0.1835516095161438\n",
            "accuracy in 45 epoch is 0.9423\n",
            "\n",
            "Loss in 46 epoch is 0.18077602982521057\n",
            "accuracy in 46 epoch is 0.9423\n",
            "\n",
            "Loss in 47 epoch is 0.17806404829025269\n",
            "accuracy in 47 epoch is 0.9423\n",
            "\n",
            "Loss in 48 epoch is 0.17543251812458038\n",
            "accuracy in 48 epoch is 0.9423\n",
            "\n",
            "Loss in 49 epoch is 0.1728951334953308\n",
            "accuracy in 49 epoch is 0.9423\n",
            "\n",
            "Loss in 50 epoch is 0.17046266794204712\n",
            "accuracy in 50 epoch is 0.9423\n",
            "\n",
            "Loss in 51 epoch is 0.16814304888248444\n",
            "accuracy in 51 epoch is 0.9423\n",
            "\n",
            "Loss in 52 epoch is 0.16594170033931732\n",
            "accuracy in 52 epoch is 0.9423\n",
            "\n",
            "Loss in 53 epoch is 0.16386160254478455\n",
            "accuracy in 53 epoch is 0.9423\n",
            "\n",
            "Loss in 54 epoch is 0.16190367937088013\n",
            "accuracy in 54 epoch is 0.9423\n",
            "\n",
            "Loss in 55 epoch is 0.16006693243980408\n",
            "accuracy in 55 epoch is 0.9423\n",
            "\n",
            "Loss in 56 epoch is 0.15834875404834747\n",
            "accuracy in 56 epoch is 0.9423\n",
            "\n",
            "Loss in 57 epoch is 0.15674515068531036\n",
            "accuracy in 57 epoch is 0.9423\n",
            "\n",
            "Loss in 58 epoch is 0.1552509218454361\n",
            "accuracy in 58 epoch is 0.9423\n",
            "\n",
            "Loss in 59 epoch is 0.15386006236076355\n",
            "accuracy in 59 epoch is 0.9423\n",
            "\n",
            "Loss in 60 epoch is 0.15256570279598236\n",
            "accuracy in 60 epoch is 0.9423\n",
            "\n",
            "Loss in 61 epoch is 0.1513606309890747\n",
            "accuracy in 61 epoch is 0.9423\n",
            "\n",
            "Loss in 62 epoch is 0.15023721754550934\n",
            "accuracy in 62 epoch is 0.9423\n",
            "\n",
            "Loss in 63 epoch is 0.14918780326843262\n",
            "accuracy in 63 epoch is 0.9423\n",
            "\n",
            "Loss in 64 epoch is 0.14820457994937897\n",
            "accuracy in 64 epoch is 0.9423\n",
            "\n",
            "Loss in 65 epoch is 0.14728015661239624\n",
            "accuracy in 65 epoch is 0.9423\n",
            "\n",
            "Loss in 66 epoch is 0.1464070975780487\n",
            "accuracy in 66 epoch is 0.9423\n",
            "\n",
            "Loss in 67 epoch is 0.145578533411026\n",
            "accuracy in 67 epoch is 0.9423\n",
            "\n",
            "Loss in 68 epoch is 0.1447879672050476\n",
            "accuracy in 68 epoch is 0.9423\n",
            "\n",
            "Loss in 69 epoch is 0.14402933418750763\n",
            "accuracy in 69 epoch is 0.9423\n",
            "\n",
            "Loss in 70 epoch is 0.14329718053340912\n",
            "accuracy in 70 epoch is 0.9423\n",
            "\n",
            "Loss in 71 epoch is 0.14258649945259094\n",
            "accuracy in 71 epoch is 0.9423\n",
            "\n",
            "Loss in 72 epoch is 0.1418929100036621\n",
            "accuracy in 72 epoch is 0.9423\n",
            "\n",
            "Loss in 73 epoch is 0.1412125825881958\n",
            "accuracy in 73 epoch is 0.9423\n",
            "\n",
            "Loss in 74 epoch is 0.14054211974143982\n",
            "accuracy in 74 epoch is 0.9423\n",
            "\n",
            "Loss in 75 epoch is 0.13987872004508972\n",
            "accuracy in 75 epoch is 0.9423\n",
            "\n",
            "Loss in 76 epoch is 0.13922004401683807\n",
            "accuracy in 76 epoch is 0.9423\n",
            "\n",
            "Loss in 77 epoch is 0.13856416940689087\n",
            "accuracy in 77 epoch is 0.9423\n",
            "\n",
            "Loss in 78 epoch is 0.13790957629680634\n",
            "accuracy in 78 epoch is 0.9423\n",
            "\n",
            "Loss in 79 epoch is 0.13725508749485016\n",
            "accuracy in 79 epoch is 0.9423\n",
            "\n",
            "Loss in 80 epoch is 0.13659988343715668\n",
            "accuracy in 80 epoch is 0.9423\n",
            "\n",
            "Loss in 81 epoch is 0.13594335317611694\n",
            "accuracy in 81 epoch is 0.9423\n",
            "\n",
            "Loss in 82 epoch is 0.1352851241827011\n",
            "accuracy in 82 epoch is 0.9423\n",
            "\n",
            "Loss in 83 epoch is 0.13462504744529724\n",
            "accuracy in 83 epoch is 0.9423\n",
            "\n",
            "Loss in 84 epoch is 0.13396307826042175\n",
            "accuracy in 84 epoch is 0.9423\n",
            "\n",
            "Loss in 85 epoch is 0.133299320936203\n",
            "accuracy in 85 epoch is 0.9423\n",
            "\n",
            "Loss in 86 epoch is 0.13263392448425293\n",
            "accuracy in 86 epoch is 0.9423\n",
            "\n",
            "Loss in 87 epoch is 0.13196715712547302\n",
            "accuracy in 87 epoch is 0.9423\n",
            "\n",
            "Loss in 88 epoch is 0.13129922747612\n",
            "accuracy in 88 epoch is 0.9423\n",
            "\n",
            "Loss in 89 epoch is 0.1306304633617401\n",
            "accuracy in 89 epoch is 0.9423\n",
            "\n",
            "Loss in 90 epoch is 0.12996113300323486\n",
            "accuracy in 90 epoch is 0.9423\n",
            "\n",
            "Loss in 91 epoch is 0.12929153442382812\n",
            "accuracy in 91 epoch is 0.9423\n",
            "\n",
            "Loss in 92 epoch is 0.128621906042099\n",
            "accuracy in 92 epoch is 0.9423\n",
            "\n",
            "Loss in 93 epoch is 0.1279524862766266\n",
            "accuracy in 93 epoch is 0.9423\n",
            "\n",
            "Loss in 94 epoch is 0.12728345394134521\n",
            "accuracy in 94 epoch is 0.9423\n",
            "\n",
            "Loss in 95 epoch is 0.1266149878501892\n",
            "accuracy in 95 epoch is 0.9423\n",
            "\n",
            "Loss in 96 epoch is 0.12594720721244812\n",
            "accuracy in 96 epoch is 0.9423\n",
            "\n",
            "Loss in 97 epoch is 0.1252802461385727\n",
            "accuracy in 97 epoch is 0.9423\n",
            "\n",
            "Loss in 98 epoch is 0.1246141567826271\n",
            "accuracy in 98 epoch is 0.9423\n",
            "\n",
            "Loss in 99 epoch is 0.12394899874925613\n",
            "accuracy in 99 epoch is 0.9487\n",
            "\n",
            "Loss in 100 epoch is 0.12328475713729858\n",
            "accuracy in 100 epoch is 0.9487\n",
            "\n",
            "Loss in 101 epoch is 0.12262143939733505\n",
            "accuracy in 101 epoch is 0.9487\n",
            "\n",
            "Loss in 102 epoch is 0.12195903807878494\n",
            "accuracy in 102 epoch is 0.9487\n",
            "\n",
            "Loss in 103 epoch is 0.12129750847816467\n",
            "accuracy in 103 epoch is 0.9487\n",
            "\n",
            "Loss in 104 epoch is 0.12063679099082947\n",
            "accuracy in 104 epoch is 0.9487\n",
            "\n",
            "Loss in 105 epoch is 0.11997684836387634\n",
            "accuracy in 105 epoch is 0.9487\n",
            "\n",
            "Loss in 106 epoch is 0.11931761354207993\n",
            "accuracy in 106 epoch is 0.9487\n",
            "\n",
            "Loss in 107 epoch is 0.11865901947021484\n",
            "accuracy in 107 epoch is 0.9487\n",
            "\n",
            "Loss in 108 epoch is 0.11800100654363632\n",
            "accuracy in 108 epoch is 0.9487\n",
            "\n",
            "Loss in 109 epoch is 0.11734350025653839\n",
            "accuracy in 109 epoch is 0.9487\n",
            "\n",
            "Loss in 110 epoch is 0.11668645590543747\n",
            "accuracy in 110 epoch is 0.9487\n",
            "\n",
            "Loss in 111 epoch is 0.11602981388568878\n",
            "accuracy in 111 epoch is 0.9487\n",
            "\n",
            "Loss in 112 epoch is 0.11537353694438934\n",
            "accuracy in 112 epoch is 0.9487\n",
            "\n",
            "Loss in 113 epoch is 0.11471758037805557\n",
            "accuracy in 113 epoch is 0.9487\n",
            "\n",
            "Loss in 114 epoch is 0.11406190693378448\n",
            "accuracy in 114 epoch is 0.9487\n",
            "\n",
            "Loss in 115 epoch is 0.11340650171041489\n",
            "accuracy in 115 epoch is 0.9487\n",
            "\n",
            "Loss in 116 epoch is 0.11275134980678558\n",
            "accuracy in 116 epoch is 0.9487\n",
            "\n",
            "Loss in 117 epoch is 0.11209642887115479\n",
            "accuracy in 117 epoch is 0.9487\n",
            "\n",
            "Loss in 118 epoch is 0.11144176870584488\n",
            "accuracy in 118 epoch is 0.9487\n",
            "\n",
            "Loss in 119 epoch is 0.11078733205795288\n",
            "accuracy in 119 epoch is 0.9487\n",
            "\n",
            "Loss in 120 epoch is 0.11013315618038177\n",
            "accuracy in 120 epoch is 0.9487\n",
            "\n",
            "Loss in 121 epoch is 0.10947924107313156\n",
            "accuracy in 121 epoch is 0.9487\n",
            "\n",
            "Loss in 122 epoch is 0.10882564634084702\n",
            "accuracy in 122 epoch is 0.9487\n",
            "\n",
            "Loss in 123 epoch is 0.10817239433526993\n",
            "accuracy in 123 epoch is 0.9487\n",
            "\n",
            "Loss in 124 epoch is 0.1075194925069809\n",
            "accuracy in 124 epoch is 0.9487\n",
            "\n",
            "Loss in 125 epoch is 0.10686700791120529\n",
            "accuracy in 125 epoch is 0.9487\n",
            "\n",
            "Loss in 126 epoch is 0.1062149778008461\n",
            "accuracy in 126 epoch is 0.9487\n",
            "\n",
            "Loss in 127 epoch is 0.1055634543299675\n",
            "accuracy in 127 epoch is 0.9487\n",
            "\n",
            "Loss in 128 epoch is 0.10491246730089188\n",
            "accuracy in 128 epoch is 0.9487\n",
            "\n",
            "Loss in 129 epoch is 0.1042621061205864\n",
            "accuracy in 129 epoch is 0.9487\n",
            "\n",
            "Loss in 130 epoch is 0.10361240804195404\n",
            "accuracy in 130 epoch is 0.9551\n",
            "\n",
            "Loss in 131 epoch is 0.10296342521905899\n",
            "accuracy in 131 epoch is 0.9551\n",
            "\n",
            "Loss in 132 epoch is 0.10231522470712662\n",
            "accuracy in 132 epoch is 0.9551\n",
            "\n",
            "Loss in 133 epoch is 0.1016678661108017\n",
            "accuracy in 133 epoch is 0.9551\n",
            "\n",
            "Loss in 134 epoch is 0.1010214239358902\n",
            "accuracy in 134 epoch is 0.9615\n",
            "\n",
            "Loss in 135 epoch is 0.1003759354352951\n",
            "accuracy in 135 epoch is 0.9615\n",
            "\n",
            "Loss in 136 epoch is 0.09973149746656418\n",
            "accuracy in 136 epoch is 0.9615\n",
            "\n",
            "Loss in 137 epoch is 0.0990881621837616\n",
            "accuracy in 137 epoch is 0.9615\n",
            "\n",
            "Loss in 138 epoch is 0.09844599664211273\n",
            "accuracy in 138 epoch is 0.9615\n",
            "\n",
            "Loss in 139 epoch is 0.09780505299568176\n",
            "accuracy in 139 epoch is 0.9615\n",
            "\n",
            "Loss in 140 epoch is 0.09716542065143585\n",
            "accuracy in 140 epoch is 0.9615\n",
            "\n",
            "Loss in 141 epoch is 0.09652715921401978\n",
            "accuracy in 141 epoch is 0.9615\n",
            "\n",
            "Loss in 142 epoch is 0.0958903431892395\n",
            "accuracy in 142 epoch is 0.9615\n",
            "\n",
            "Loss in 143 epoch is 0.09525501728057861\n",
            "accuracy in 143 epoch is 0.9615\n",
            "\n",
            "Loss in 144 epoch is 0.09462128579616547\n",
            "accuracy in 144 epoch is 0.9615\n",
            "\n",
            "Loss in 145 epoch is 0.09398918598890305\n",
            "accuracy in 145 epoch is 0.9615\n",
            "\n",
            "Loss in 146 epoch is 0.09335882216691971\n",
            "accuracy in 146 epoch is 0.9615\n",
            "\n",
            "Loss in 147 epoch is 0.09273022413253784\n",
            "accuracy in 147 epoch is 0.9615\n",
            "\n",
            "Loss in 148 epoch is 0.0921034887433052\n",
            "accuracy in 148 epoch is 0.9615\n",
            "\n",
            "Loss in 149 epoch is 0.09147866070270538\n",
            "accuracy in 149 epoch is 0.9615\n",
            "\n",
            "Loss in 150 epoch is 0.09085582196712494\n",
            "accuracy in 150 epoch is 0.9615\n",
            "\n",
            "Loss in 151 epoch is 0.09023503959178925\n",
            "accuracy in 151 epoch is 0.9615\n",
            "\n",
            "Loss in 152 epoch is 0.08961638063192368\n",
            "accuracy in 152 epoch is 0.9615\n",
            "\n",
            "Loss in 153 epoch is 0.088999904692173\n",
            "accuracy in 153 epoch is 0.9615\n",
            "\n",
            "Loss in 154 epoch is 0.0883856937289238\n",
            "accuracy in 154 epoch is 0.9615\n",
            "\n",
            "Loss in 155 epoch is 0.08777378499507904\n",
            "accuracy in 155 epoch is 0.9615\n",
            "\n",
            "Loss in 156 epoch is 0.08716428279876709\n",
            "accuracy in 156 epoch is 0.9615\n",
            "\n",
            "Loss in 157 epoch is 0.08655723184347153\n",
            "accuracy in 157 epoch is 0.9615\n",
            "\n",
            "Loss in 158 epoch is 0.08595267683267593\n",
            "accuracy in 158 epoch is 0.9615\n",
            "\n",
            "Loss in 159 epoch is 0.08535069972276688\n",
            "accuracy in 159 epoch is 0.9615\n",
            "\n",
            "Loss in 160 epoch is 0.08475135266780853\n",
            "accuracy in 160 epoch is 0.9615\n",
            "\n",
            "Loss in 161 epoch is 0.08415469527244568\n",
            "accuracy in 161 epoch is 0.9679\n",
            "\n",
            "Loss in 162 epoch is 0.08356079459190369\n",
            "accuracy in 162 epoch is 0.9679\n",
            "\n",
            "Loss in 163 epoch is 0.08296968787908554\n",
            "accuracy in 163 epoch is 0.9679\n",
            "\n",
            "Loss in 164 epoch is 0.08238144963979721\n",
            "accuracy in 164 epoch is 0.9679\n",
            "\n",
            "Loss in 165 epoch is 0.08179611712694168\n",
            "accuracy in 165 epoch is 0.9679\n",
            "\n",
            "Loss in 166 epoch is 0.08121376484632492\n",
            "accuracy in 166 epoch is 0.9679\n",
            "\n",
            "Loss in 167 epoch is 0.08063440769910812\n",
            "accuracy in 167 epoch is 0.9679\n",
            "\n",
            "Loss in 168 epoch is 0.08005811274051666\n",
            "accuracy in 168 epoch is 0.9679\n",
            "\n",
            "Loss in 169 epoch is 0.07948492467403412\n",
            "accuracy in 169 epoch is 0.9679\n",
            "\n",
            "Loss in 170 epoch is 0.07891488075256348\n",
            "accuracy in 170 epoch is 0.9679\n",
            "\n",
            "Loss in 171 epoch is 0.07834803313016891\n",
            "accuracy in 171 epoch is 0.9679\n",
            "\n",
            "Loss in 172 epoch is 0.07778441160917282\n",
            "accuracy in 172 epoch is 0.9679\n",
            "\n",
            "Loss in 173 epoch is 0.07722404599189758\n",
            "accuracy in 173 epoch is 0.9744\n",
            "\n",
            "Loss in 174 epoch is 0.07666698843240738\n",
            "accuracy in 174 epoch is 0.9744\n",
            "\n",
            "Loss in 175 epoch is 0.0761132538318634\n",
            "accuracy in 175 epoch is 0.9744\n",
            "\n",
            "Loss in 176 epoch is 0.07556289434432983\n",
            "accuracy in 176 epoch is 0.9744\n",
            "\n",
            "Loss in 177 epoch is 0.07501591742038727\n",
            "accuracy in 177 epoch is 0.9744\n",
            "\n",
            "Loss in 178 epoch is 0.0744723454117775\n",
            "accuracy in 178 epoch is 0.9744\n",
            "\n",
            "Loss in 179 epoch is 0.0739322304725647\n",
            "accuracy in 179 epoch is 0.9744\n",
            "\n",
            "Loss in 180 epoch is 0.07339555770158768\n",
            "accuracy in 180 epoch is 0.9744\n",
            "\n",
            "Loss in 181 epoch is 0.07286237180233002\n",
            "accuracy in 181 epoch is 0.9744\n",
            "\n",
            "Loss in 182 epoch is 0.07233268022537231\n",
            "accuracy in 182 epoch is 0.9744\n",
            "\n",
            "Loss in 183 epoch is 0.07180649787187576\n",
            "accuracy in 183 epoch is 0.9744\n",
            "\n",
            "Loss in 184 epoch is 0.07128383219242096\n",
            "accuracy in 184 epoch is 0.9744\n",
            "\n",
            "Loss in 185 epoch is 0.0707646980881691\n",
            "accuracy in 185 epoch is 0.9744\n",
            "\n",
            "Loss in 186 epoch is 0.07024910300970078\n",
            "accuracy in 186 epoch is 0.9808\n",
            "\n",
            "Loss in 187 epoch is 0.06973705440759659\n",
            "accuracy in 187 epoch is 0.9808\n",
            "\n",
            "Loss in 188 epoch is 0.06922856718301773\n",
            "accuracy in 188 epoch is 0.9808\n",
            "\n",
            "Loss in 189 epoch is 0.06872361898422241\n",
            "accuracy in 189 epoch is 0.9808\n",
            "\n",
            "Loss in 190 epoch is 0.06822222471237183\n",
            "accuracy in 190 epoch is 0.9808\n",
            "\n",
            "Loss in 191 epoch is 0.06772437691688538\n",
            "accuracy in 191 epoch is 0.9808\n",
            "\n",
            "Loss in 192 epoch is 0.06723008304834366\n",
            "accuracy in 192 epoch is 0.9808\n",
            "\n",
            "Loss in 193 epoch is 0.06673932820558548\n",
            "accuracy in 193 epoch is 0.9808\n",
            "\n",
            "Loss in 194 epoch is 0.06625211983919144\n",
            "accuracy in 194 epoch is 0.9808\n",
            "\n",
            "Loss in 195 epoch is 0.06576843559741974\n",
            "accuracy in 195 epoch is 0.9808\n",
            "\n",
            "Loss in 196 epoch is 0.06528826802968979\n",
            "accuracy in 196 epoch is 0.9808\n",
            "\n",
            "Loss in 197 epoch is 0.06481162458658218\n",
            "accuracy in 197 epoch is 0.9808\n",
            "\n",
            "Loss in 198 epoch is 0.06433846801519394\n",
            "accuracy in 198 epoch is 0.9808\n",
            "\n",
            "Loss in 199 epoch is 0.06386880576610565\n",
            "accuracy in 199 epoch is 0.9808\n",
            "\n",
            "Loss in 200 epoch is 0.06340261548757553\n",
            "accuracy in 200 epoch is 0.9808\n",
            "\n",
            "Loss in 201 epoch is 0.06293988227844238\n",
            "accuracy in 201 epoch is 0.9872\n",
            "\n",
            "Loss in 202 epoch is 0.062480583786964417\n",
            "accuracy in 202 epoch is 0.9872\n",
            "\n",
            "Loss in 203 epoch is 0.06202472746372223\n",
            "accuracy in 203 epoch is 0.9872\n",
            "\n",
            "Loss in 204 epoch is 0.061572276055812836\n",
            "accuracy in 204 epoch is 0.9872\n",
            "\n",
            "Loss in 205 epoch is 0.06112322583794594\n",
            "accuracy in 205 epoch is 0.9872\n",
            "\n",
            "Loss in 206 epoch is 0.060677554458379745\n",
            "accuracy in 206 epoch is 0.9872\n",
            "\n",
            "Loss in 207 epoch is 0.06023522466421127\n",
            "accuracy in 207 epoch is 0.9872\n",
            "\n",
            "Loss in 208 epoch is 0.05979624018073082\n",
            "accuracy in 208 epoch is 0.9872\n",
            "\n",
            "Loss in 209 epoch is 0.059360578656196594\n",
            "accuracy in 209 epoch is 0.9936\n",
            "\n",
            "Loss in 210 epoch is 0.058928221464157104\n",
            "accuracy in 210 epoch is 0.9936\n",
            "\n",
            "Loss in 211 epoch is 0.05849914625287056\n",
            "accuracy in 211 epoch is 0.9936\n",
            "\n",
            "Loss in 212 epoch is 0.058073319494724274\n",
            "accuracy in 212 epoch is 0.9936\n",
            "\n",
            "Loss in 213 epoch is 0.05765073746442795\n",
            "accuracy in 213 epoch is 0.9936\n",
            "\n",
            "Loss in 214 epoch is 0.057231370359659195\n",
            "accuracy in 214 epoch is 0.9936\n",
            "\n",
            "Loss in 215 epoch is 0.05681522563099861\n",
            "accuracy in 215 epoch is 0.9936\n",
            "\n",
            "Loss in 216 epoch is 0.05640224367380142\n",
            "accuracy in 216 epoch is 0.9936\n",
            "\n",
            "Loss in 217 epoch is 0.05599243938922882\n",
            "accuracy in 217 epoch is 0.9936\n",
            "\n",
            "Loss in 218 epoch is 0.05558575689792633\n",
            "accuracy in 218 epoch is 0.9936\n",
            "\n",
            "Loss in 219 epoch is 0.05518220737576485\n",
            "accuracy in 219 epoch is 0.9936\n",
            "\n",
            "Loss in 220 epoch is 0.054781753569841385\n",
            "accuracy in 220 epoch is 0.9936\n",
            "\n",
            "Loss in 221 epoch is 0.054384391754865646\n",
            "accuracy in 221 epoch is 0.9936\n",
            "\n",
            "Loss in 222 epoch is 0.053990088403224945\n",
            "accuracy in 222 epoch is 0.9936\n",
            "\n",
            "Loss in 223 epoch is 0.053598832339048386\n",
            "accuracy in 223 epoch is 0.9936\n",
            "\n",
            "Loss in 224 epoch is 0.05321060121059418\n",
            "accuracy in 224 epoch is 0.9936\n",
            "\n",
            "Loss in 225 epoch is 0.05282536521553993\n",
            "accuracy in 225 epoch is 0.9936\n",
            "\n",
            "Loss in 226 epoch is 0.052443139255046844\n",
            "accuracy in 226 epoch is 0.9936\n",
            "\n",
            "Loss in 227 epoch is 0.05206386372447014\n",
            "accuracy in 227 epoch is 0.9936\n",
            "\n",
            "Loss in 228 epoch is 0.05168755725026131\n",
            "accuracy in 228 epoch is 0.9936\n",
            "\n",
            "Loss in 229 epoch is 0.05131419003009796\n",
            "accuracy in 229 epoch is 0.9936\n",
            "\n",
            "Loss in 230 epoch is 0.05094373598694801\n",
            "accuracy in 230 epoch is 0.9936\n",
            "\n",
            "Loss in 231 epoch is 0.05057616904377937\n",
            "accuracy in 231 epoch is 0.9936\n",
            "\n",
            "Loss in 232 epoch is 0.05021150782704353\n",
            "accuracy in 232 epoch is 0.9936\n",
            "\n",
            "Loss in 233 epoch is 0.04984970763325691\n",
            "accuracy in 233 epoch is 0.9936\n",
            "\n",
            "Loss in 234 epoch is 0.049490753561258316\n",
            "accuracy in 234 epoch is 0.9936\n",
            "\n",
            "Loss in 235 epoch is 0.04913465678691864\n",
            "accuracy in 235 epoch is 0.9936\n",
            "\n",
            "Loss in 236 epoch is 0.04878135770559311\n",
            "accuracy in 236 epoch is 0.9936\n",
            "\n",
            "Loss in 237 epoch is 0.048430878669023514\n",
            "accuracy in 237 epoch is 1.0\n",
            "\n",
            "Loss in 238 epoch is 0.04808318614959717\n",
            "accuracy in 238 epoch is 1.0\n",
            "\n",
            "Loss in 239 epoch is 0.047738272696733475\n",
            "accuracy in 239 epoch is 1.0\n",
            "\n",
            "Loss in 240 epoch is 0.047396112233400345\n",
            "accuracy in 240 epoch is 1.0\n",
            "\n",
            "Loss in 241 epoch is 0.04705670103430748\n",
            "accuracy in 241 epoch is 1.0\n",
            "\n",
            "Loss in 242 epoch is 0.04672001674771309\n",
            "accuracy in 242 epoch is 1.0\n",
            "\n",
            "Loss in 243 epoch is 0.04638604447245598\n",
            "accuracy in 243 epoch is 1.0\n",
            "\n",
            "Loss in 244 epoch is 0.04605479538440704\n",
            "accuracy in 244 epoch is 1.0\n",
            "\n",
            "Loss in 245 epoch is 0.04572620615363121\n",
            "accuracy in 245 epoch is 1.0\n",
            "\n",
            "Loss in 246 epoch is 0.045400310307741165\n",
            "accuracy in 246 epoch is 1.0\n",
            "\n",
            "Loss in 247 epoch is 0.04507705941796303\n",
            "accuracy in 247 epoch is 1.0\n",
            "\n",
            "Loss in 248 epoch is 0.044756460934877396\n",
            "accuracy in 248 epoch is 1.0\n",
            "\n",
            "Loss in 249 epoch is 0.04443848878145218\n",
            "accuracy in 249 epoch is 1.0\n",
            "\n",
            "Loss in 250 epoch is 0.04412313550710678\n",
            "accuracy in 250 epoch is 1.0\n",
            "\n",
            "Loss in 251 epoch is 0.04381038248538971\n",
            "accuracy in 251 epoch is 1.0\n",
            "\n",
            "Loss in 252 epoch is 0.043500225991010666\n",
            "accuracy in 252 epoch is 1.0\n",
            "\n",
            "Loss in 253 epoch is 0.043192632496356964\n",
            "accuracy in 253 epoch is 1.0\n",
            "\n",
            "Loss in 254 epoch is 0.04288759455084801\n",
            "accuracy in 254 epoch is 1.0\n",
            "\n",
            "Loss in 255 epoch is 0.042585115879774094\n",
            "accuracy in 255 epoch is 1.0\n",
            "\n",
            "Loss in 256 epoch is 0.04228516295552254\n",
            "accuracy in 256 epoch is 1.0\n",
            "\n",
            "Loss in 257 epoch is 0.04198771342635155\n",
            "accuracy in 257 epoch is 1.0\n",
            "\n",
            "Loss in 258 epoch is 0.04169277846813202\n",
            "accuracy in 258 epoch is 1.0\n",
            "\n",
            "Loss in 259 epoch is 0.04140032082796097\n",
            "accuracy in 259 epoch is 1.0\n",
            "\n",
            "Loss in 260 epoch is 0.04111035540699959\n",
            "accuracy in 260 epoch is 1.0\n",
            "\n",
            "Loss in 261 epoch is 0.0408228375017643\n",
            "accuracy in 261 epoch is 1.0\n",
            "\n",
            "Loss in 262 epoch is 0.040537748485803604\n",
            "accuracy in 262 epoch is 1.0\n",
            "\n",
            "Loss in 263 epoch is 0.0402551107108593\n",
            "accuracy in 263 epoch is 1.0\n",
            "\n",
            "Loss in 264 epoch is 0.0399748720228672\n",
            "accuracy in 264 epoch is 1.0\n",
            "\n",
            "Loss in 265 epoch is 0.03969704359769821\n",
            "accuracy in 265 epoch is 1.0\n",
            "\n",
            "Loss in 266 epoch is 0.039421599358320236\n",
            "accuracy in 266 epoch is 1.0\n",
            "\n",
            "Loss in 267 epoch is 0.039148516952991486\n",
            "accuracy in 267 epoch is 1.0\n",
            "\n",
            "Loss in 268 epoch is 0.03887778893113136\n",
            "accuracy in 268 epoch is 1.0\n",
            "\n",
            "Loss in 269 epoch is 0.03860940411686897\n",
            "accuracy in 269 epoch is 1.0\n",
            "\n",
            "Loss in 270 epoch is 0.03834333270788193\n",
            "accuracy in 270 epoch is 1.0\n",
            "\n",
            "Loss in 271 epoch is 0.038079578429460526\n",
            "accuracy in 271 epoch is 1.0\n",
            "\n",
            "Loss in 272 epoch is 0.03781810775399208\n",
            "accuracy in 272 epoch is 1.0\n",
            "\n",
            "Loss in 273 epoch is 0.037558913230895996\n",
            "accuracy in 273 epoch is 1.0\n",
            "\n",
            "Loss in 274 epoch is 0.037301987409591675\n",
            "accuracy in 274 epoch is 1.0\n",
            "\n",
            "Loss in 275 epoch is 0.03704729303717613\n",
            "accuracy in 275 epoch is 1.0\n",
            "\n",
            "Loss in 276 epoch is 0.03679483011364937\n",
            "accuracy in 276 epoch is 1.0\n",
            "\n",
            "Loss in 277 epoch is 0.03654458746314049\n",
            "accuracy in 277 epoch is 1.0\n",
            "\n",
            "Loss in 278 epoch is 0.0362965390086174\n",
            "accuracy in 278 epoch is 1.0\n",
            "\n",
            "Loss in 279 epoch is 0.036050669848918915\n",
            "accuracy in 279 epoch is 1.0\n",
            "\n",
            "Loss in 280 epoch is 0.03580695763230324\n",
            "accuracy in 280 epoch is 1.0\n",
            "\n",
            "Loss in 281 epoch is 0.035565394908189774\n",
            "accuracy in 281 epoch is 1.0\n",
            "\n",
            "Loss in 282 epoch is 0.035325970500707626\n",
            "accuracy in 282 epoch is 1.0\n",
            "\n",
            "Loss in 283 epoch is 0.03508865833282471\n",
            "accuracy in 283 epoch is 1.0\n",
            "\n",
            "Loss in 284 epoch is 0.03485343977808952\n",
            "accuracy in 284 epoch is 1.0\n",
            "\n",
            "Loss in 285 epoch is 0.03462031111121178\n",
            "accuracy in 285 epoch is 1.0\n",
            "\n",
            "Loss in 286 epoch is 0.034389249980449677\n",
            "accuracy in 286 epoch is 1.0\n",
            "\n",
            "Loss in 287 epoch is 0.03416023030877113\n",
            "accuracy in 287 epoch is 1.0\n",
            "\n",
            "Loss in 288 epoch is 0.03393324092030525\n",
            "accuracy in 288 epoch is 1.0\n",
            "\n",
            "Loss in 289 epoch is 0.03370828181505203\n",
            "accuracy in 289 epoch is 1.0\n",
            "\n",
            "Loss in 290 epoch is 0.033485304564237595\n",
            "accuracy in 290 epoch is 1.0\n",
            "\n",
            "Loss in 291 epoch is 0.03326432779431343\n",
            "accuracy in 291 epoch is 1.0\n",
            "\n",
            "Loss in 292 epoch is 0.033045317977666855\n",
            "accuracy in 292 epoch is 1.0\n",
            "\n",
            "Loss in 293 epoch is 0.03282824531197548\n",
            "accuracy in 293 epoch is 1.0\n",
            "\n",
            "Loss in 294 epoch is 0.0326131135225296\n",
            "accuracy in 294 epoch is 1.0\n",
            "\n",
            "Loss in 295 epoch is 0.03239990025758743\n",
            "accuracy in 295 epoch is 1.0\n",
            "\n",
            "Loss in 296 epoch is 0.03218859061598778\n",
            "accuracy in 296 epoch is 1.0\n",
            "\n",
            "Loss in 297 epoch is 0.031979162245988846\n",
            "accuracy in 297 epoch is 1.0\n",
            "\n",
            "Loss in 298 epoch is 0.03177161142230034\n",
            "accuracy in 298 epoch is 1.0\n",
            "\n",
            "Loss in 299 epoch is 0.03156590834259987\n",
            "accuracy in 299 epoch is 1.0\n",
            "\n",
            "Loss in 300 epoch is 0.03136203810572624\n",
            "accuracy in 300 epoch is 1.0\n",
            "\n",
            "Loss in 301 epoch is 0.03115999326109886\n",
            "accuracy in 301 epoch is 1.0\n",
            "\n",
            "Loss in 302 epoch is 0.030959753319621086\n",
            "accuracy in 302 epoch is 1.0\n",
            "\n",
            "Loss in 303 epoch is 0.030761297792196274\n",
            "accuracy in 303 epoch is 1.0\n",
            "\n",
            "Loss in 304 epoch is 0.03056461364030838\n",
            "accuracy in 304 epoch is 1.0\n",
            "\n",
            "Loss in 305 epoch is 0.03036968596279621\n",
            "accuracy in 305 epoch is 1.0\n",
            "\n",
            "Loss in 306 epoch is 0.030176501721143723\n",
            "accuracy in 306 epoch is 1.0\n",
            "\n",
            "Loss in 307 epoch is 0.029985040426254272\n",
            "accuracy in 307 epoch is 1.0\n",
            "\n",
            "Loss in 308 epoch is 0.02979528345167637\n",
            "accuracy in 308 epoch is 1.0\n",
            "\n",
            "Loss in 309 epoch is 0.029607219621539116\n",
            "accuracy in 309 epoch is 1.0\n",
            "\n",
            "Loss in 310 epoch is 0.02942083775997162\n",
            "accuracy in 310 epoch is 1.0\n",
            "\n",
            "Loss in 311 epoch is 0.029236115515232086\n",
            "accuracy in 311 epoch is 1.0\n",
            "\n",
            "Loss in 312 epoch is 0.029053039848804474\n",
            "accuracy in 312 epoch is 1.0\n",
            "\n",
            "Loss in 313 epoch is 0.02887159213423729\n",
            "accuracy in 313 epoch is 1.0\n",
            "\n",
            "Loss in 314 epoch is 0.028691768646240234\n",
            "accuracy in 314 epoch is 1.0\n",
            "\n",
            "Loss in 315 epoch is 0.028513535857200623\n",
            "accuracy in 315 epoch is 1.0\n",
            "\n",
            "Loss in 316 epoch is 0.028336895629763603\n",
            "accuracy in 316 epoch is 1.0\n",
            "\n",
            "Loss in 317 epoch is 0.028161820024251938\n",
            "accuracy in 317 epoch is 1.0\n",
            "\n",
            "Loss in 318 epoch is 0.027988305315375328\n",
            "accuracy in 318 epoch is 1.0\n",
            "\n",
            "Loss in 319 epoch is 0.027816325426101685\n",
            "accuracy in 319 epoch is 1.0\n",
            "\n",
            "Loss in 320 epoch is 0.027645869180560112\n",
            "accuracy in 320 epoch is 1.0\n",
            "\n",
            "Loss in 321 epoch is 0.027476927265524864\n",
            "accuracy in 321 epoch is 1.0\n",
            "\n",
            "Loss in 322 epoch is 0.027309484779834747\n",
            "accuracy in 322 epoch is 1.0\n",
            "\n",
            "Loss in 323 epoch is 0.02714352123439312\n",
            "accuracy in 323 epoch is 1.0\n",
            "\n",
            "Loss in 324 epoch is 0.026979027315974236\n",
            "accuracy in 324 epoch is 1.0\n",
            "\n",
            "Loss in 325 epoch is 0.026815980672836304\n",
            "accuracy in 325 epoch is 1.0\n",
            "\n",
            "Loss in 326 epoch is 0.026654383167624474\n",
            "accuracy in 326 epoch is 1.0\n",
            "\n",
            "Loss in 327 epoch is 0.026494203135371208\n",
            "accuracy in 327 epoch is 1.0\n",
            "\n",
            "Loss in 328 epoch is 0.02633543871343136\n",
            "accuracy in 328 epoch is 1.0\n",
            "\n",
            "Loss in 329 epoch is 0.026178065687417984\n",
            "accuracy in 329 epoch is 1.0\n",
            "\n",
            "Loss in 330 epoch is 0.026022085919976234\n",
            "accuracy in 330 epoch is 1.0\n",
            "\n",
            "Loss in 331 epoch is 0.025867465883493423\n",
            "accuracy in 331 epoch is 1.0\n",
            "\n",
            "Loss in 332 epoch is 0.025714201852679253\n",
            "accuracy in 332 epoch is 1.0\n",
            "\n",
            "Loss in 333 epoch is 0.025562291964888573\n",
            "accuracy in 333 epoch is 1.0\n",
            "\n",
            "Loss in 334 epoch is 0.025411710143089294\n",
            "accuracy in 334 epoch is 1.0\n",
            "\n",
            "Loss in 335 epoch is 0.025262441486120224\n",
            "accuracy in 335 epoch is 1.0\n",
            "\n",
            "Loss in 336 epoch is 0.025114472955465317\n",
            "accuracy in 336 epoch is 1.0\n",
            "\n",
            "Loss in 337 epoch is 0.024967791512608528\n",
            "accuracy in 337 epoch is 1.0\n",
            "\n",
            "Loss in 338 epoch is 0.024822400882840157\n",
            "accuracy in 338 epoch is 1.0\n",
            "\n",
            "Loss in 339 epoch is 0.024678273126482964\n",
            "accuracy in 339 epoch is 1.0\n",
            "\n",
            "Loss in 340 epoch is 0.024535391479730606\n",
            "accuracy in 340 epoch is 1.0\n",
            "\n",
            "Loss in 341 epoch is 0.024393750354647636\n",
            "accuracy in 341 epoch is 1.0\n",
            "\n",
            "Loss in 342 epoch is 0.024253344163298607\n",
            "accuracy in 342 epoch is 1.0\n",
            "\n",
            "Loss in 343 epoch is 0.02411414496600628\n",
            "accuracy in 343 epoch is 1.0\n",
            "\n",
            "Loss in 344 epoch is 0.023976150900125504\n",
            "accuracy in 344 epoch is 1.0\n",
            "\n",
            "Loss in 345 epoch is 0.023839348927140236\n",
            "accuracy in 345 epoch is 1.0\n",
            "\n",
            "Loss in 346 epoch is 0.02370372787117958\n",
            "accuracy in 346 epoch is 1.0\n",
            "\n",
            "Loss in 347 epoch is 0.023569272831082344\n",
            "accuracy in 347 epoch is 1.0\n",
            "\n",
            "Loss in 348 epoch is 0.02343597076833248\n",
            "accuracy in 348 epoch is 1.0\n",
            "\n",
            "Loss in 349 epoch is 0.023303816094994545\n",
            "accuracy in 349 epoch is 1.0\n",
            "\n",
            "Loss in 350 epoch is 0.023172792047262192\n",
            "accuracy in 350 epoch is 1.0\n",
            "\n",
            "Loss in 351 epoch is 0.023042887449264526\n",
            "accuracy in 351 epoch is 1.0\n",
            "\n",
            "Loss in 352 epoch is 0.022914089262485504\n",
            "accuracy in 352 epoch is 1.0\n",
            "\n",
            "Loss in 353 epoch is 0.022786399349570274\n",
            "accuracy in 353 epoch is 1.0\n",
            "\n",
            "Loss in 354 epoch is 0.02265978418290615\n",
            "accuracy in 354 epoch is 1.0\n",
            "\n",
            "Loss in 355 epoch is 0.02253425493836403\n",
            "accuracy in 355 epoch is 1.0\n",
            "\n",
            "Loss in 356 epoch is 0.02240978553891182\n",
            "accuracy in 356 epoch is 1.0\n",
            "\n",
            "Loss in 357 epoch is 0.022286375984549522\n",
            "accuracy in 357 epoch is 1.0\n",
            "\n",
            "Loss in 358 epoch is 0.022164007648825645\n",
            "accuracy in 358 epoch is 1.0\n",
            "\n",
            "Loss in 359 epoch is 0.022042671218514442\n",
            "accuracy in 359 epoch is 1.0\n",
            "\n",
            "Loss in 360 epoch is 0.021922362968325615\n",
            "accuracy in 360 epoch is 1.0\n",
            "\n",
            "Loss in 361 epoch is 0.021803058683872223\n",
            "accuracy in 361 epoch is 1.0\n",
            "\n",
            "Loss in 362 epoch is 0.021684762090444565\n",
            "accuracy in 362 epoch is 1.0\n",
            "\n",
            "Loss in 363 epoch is 0.021567456424236298\n",
            "accuracy in 363 epoch is 1.0\n",
            "\n",
            "Loss in 364 epoch is 0.021451130509376526\n",
            "accuracy in 364 epoch is 1.0\n",
            "\n",
            "Loss in 365 epoch is 0.02133578434586525\n",
            "accuracy in 365 epoch is 1.0\n",
            "\n",
            "Loss in 366 epoch is 0.02122139371931553\n",
            "accuracy in 366 epoch is 1.0\n",
            "\n",
            "Loss in 367 epoch is 0.021107962355017662\n",
            "accuracy in 367 epoch is 1.0\n",
            "\n",
            "Loss in 368 epoch is 0.02099546603858471\n",
            "accuracy in 368 epoch is 1.0\n",
            "\n",
            "Loss in 369 epoch is 0.02088390290737152\n",
            "accuracy in 369 epoch is 1.0\n",
            "\n",
            "Loss in 370 epoch is 0.02077326737344265\n",
            "accuracy in 370 epoch is 1.0\n",
            "\n",
            "Loss in 371 epoch is 0.020663542672991753\n",
            "accuracy in 371 epoch is 1.0\n",
            "\n",
            "Loss in 372 epoch is 0.020554734393954277\n",
            "accuracy in 372 epoch is 1.0\n",
            "\n",
            "Loss in 373 epoch is 0.020446810871362686\n",
            "accuracy in 373 epoch is 1.0\n",
            "\n",
            "Loss in 374 epoch is 0.020339783281087875\n",
            "accuracy in 374 epoch is 1.0\n",
            "\n",
            "Loss in 375 epoch is 0.020233623683452606\n",
            "accuracy in 375 epoch is 1.0\n",
            "\n",
            "Loss in 376 epoch is 0.020128339529037476\n",
            "accuracy in 376 epoch is 1.0\n",
            "\n",
            "Loss in 377 epoch is 0.02002391777932644\n",
            "accuracy in 377 epoch is 1.0\n",
            "\n",
            "Loss in 378 epoch is 0.0199203472584486\n",
            "accuracy in 378 epoch is 1.0\n",
            "\n",
            "Loss in 379 epoch is 0.019817620515823364\n",
            "accuracy in 379 epoch is 1.0\n",
            "\n",
            "Loss in 380 epoch is 0.01971571519970894\n",
            "accuracy in 380 epoch is 1.0\n",
            "\n",
            "Loss in 381 epoch is 0.019614653661847115\n",
            "accuracy in 381 epoch is 1.0\n",
            "\n",
            "Loss in 382 epoch is 0.019514406099915504\n",
            "accuracy in 382 epoch is 1.0\n",
            "\n",
            "Loss in 383 epoch is 0.01941496878862381\n",
            "accuracy in 383 epoch is 1.0\n",
            "\n",
            "Loss in 384 epoch is 0.019316328689455986\n",
            "accuracy in 384 epoch is 1.0\n",
            "\n",
            "Loss in 385 epoch is 0.019218483939766884\n",
            "accuracy in 385 epoch is 1.0\n",
            "\n",
            "Loss in 386 epoch is 0.019121427088975906\n",
            "accuracy in 386 epoch is 1.0\n",
            "\n",
            "Loss in 387 epoch is 0.01902514323592186\n",
            "accuracy in 387 epoch is 1.0\n",
            "\n",
            "Loss in 388 epoch is 0.018929630517959595\n",
            "accuracy in 388 epoch is 1.0\n",
            "\n",
            "Loss in 389 epoch is 0.018834885209798813\n",
            "accuracy in 389 epoch is 1.0\n",
            "\n",
            "Loss in 390 epoch is 0.01874089241027832\n",
            "accuracy in 390 epoch is 1.0\n",
            "\n",
            "Loss in 391 epoch is 0.01864764280617237\n",
            "accuracy in 391 epoch is 1.0\n",
            "\n",
            "Loss in 392 epoch is 0.018555138260126114\n",
            "accuracy in 392 epoch is 1.0\n",
            "\n",
            "Loss in 393 epoch is 0.018463362008333206\n",
            "accuracy in 393 epoch is 1.0\n",
            "\n",
            "Loss in 394 epoch is 0.018372315913438797\n",
            "accuracy in 394 epoch is 1.0\n",
            "\n",
            "Loss in 395 epoch is 0.018281983211636543\n",
            "accuracy in 395 epoch is 1.0\n",
            "\n",
            "Loss in 396 epoch is 0.018192360177636147\n",
            "accuracy in 396 epoch is 1.0\n",
            "\n",
            "Loss in 397 epoch is 0.01810344122350216\n",
            "accuracy in 397 epoch is 1.0\n",
            "\n",
            "Loss in 398 epoch is 0.018015224486589432\n",
            "accuracy in 398 epoch is 1.0\n",
            "\n",
            "Loss in 399 epoch is 0.01792769879102707\n",
            "accuracy in 399 epoch is 1.0\n",
            "\n",
            "Loss in 400 epoch is 0.017840847373008728\n",
            "accuracy in 400 epoch is 1.0\n",
            "\n",
            "Loss in 401 epoch is 0.017754677683115005\n",
            "accuracy in 401 epoch is 1.0\n",
            "\n",
            "Loss in 402 epoch is 0.01766917109489441\n",
            "accuracy in 402 epoch is 1.0\n",
            "\n",
            "Loss in 403 epoch is 0.017584333196282387\n",
            "accuracy in 403 epoch is 1.0\n",
            "\n",
            "Loss in 404 epoch is 0.017500147223472595\n",
            "accuracy in 404 epoch is 1.0\n",
            "\n",
            "Loss in 405 epoch is 0.017416616901755333\n",
            "accuracy in 405 epoch is 1.0\n",
            "\n",
            "Loss in 406 epoch is 0.017333725467324257\n",
            "accuracy in 406 epoch is 1.0\n",
            "\n",
            "Loss in 407 epoch is 0.017251476645469666\n",
            "accuracy in 407 epoch is 1.0\n",
            "\n",
            "Loss in 408 epoch is 0.017169853672385216\n",
            "accuracy in 408 epoch is 1.0\n",
            "\n",
            "Loss in 409 epoch is 0.01708885468542576\n",
            "accuracy in 409 epoch is 1.0\n",
            "\n",
            "Loss in 410 epoch is 0.017008475959300995\n",
            "accuracy in 410 epoch is 1.0\n",
            "\n",
            "Loss in 411 epoch is 0.01692871004343033\n",
            "accuracy in 411 epoch is 1.0\n",
            "\n",
            "Loss in 412 epoch is 0.016849549487233162\n",
            "accuracy in 412 epoch is 1.0\n",
            "\n",
            "Loss in 413 epoch is 0.016770996153354645\n",
            "accuracy in 413 epoch is 1.0\n",
            "\n",
            "Loss in 414 epoch is 0.016693023964762688\n",
            "accuracy in 414 epoch is 1.0\n",
            "\n",
            "Loss in 415 epoch is 0.016615653410553932\n",
            "accuracy in 415 epoch is 1.0\n",
            "\n",
            "Loss in 416 epoch is 0.01653885841369629\n",
            "accuracy in 416 epoch is 1.0\n",
            "\n",
            "Loss in 417 epoch is 0.01646263897418976\n",
            "accuracy in 417 epoch is 1.0\n",
            "\n",
            "Loss in 418 epoch is 0.016387000679969788\n",
            "accuracy in 418 epoch is 1.0\n",
            "\n",
            "Loss in 419 epoch is 0.016311926767230034\n",
            "accuracy in 419 epoch is 1.0\n",
            "\n",
            "Loss in 420 epoch is 0.01623740792274475\n",
            "accuracy in 420 epoch is 1.0\n",
            "\n",
            "Loss in 421 epoch is 0.016163447871804237\n",
            "accuracy in 421 epoch is 1.0\n",
            "\n",
            "Loss in 422 epoch is 0.016090041026473045\n",
            "accuracy in 422 epoch is 1.0\n",
            "\n",
            "Loss in 423 epoch is 0.01601717807352543\n",
            "accuracy in 423 epoch is 1.0\n",
            "\n",
            "Loss in 424 epoch is 0.01594484969973564\n",
            "accuracy in 424 epoch is 1.0\n",
            "\n",
            "Loss in 425 epoch is 0.015873059630393982\n",
            "accuracy in 425 epoch is 1.0\n",
            "\n",
            "Loss in 426 epoch is 0.015801798552274704\n",
            "accuracy in 426 epoch is 1.0\n",
            "\n",
            "Loss in 427 epoch is 0.01573105715215206\n",
            "accuracy in 427 epoch is 1.0\n",
            "\n",
            "Loss in 428 epoch is 0.01566084288060665\n",
            "accuracy in 428 epoch is 1.0\n",
            "\n",
            "Loss in 429 epoch is 0.015591137111186981\n",
            "accuracy in 429 epoch is 1.0\n",
            "\n",
            "Loss in 430 epoch is 0.015521946363151073\n",
            "accuracy in 430 epoch is 1.0\n",
            "\n",
            "Loss in 431 epoch is 0.01545325294137001\n",
            "accuracy in 431 epoch is 1.0\n",
            "\n",
            "Loss in 432 epoch is 0.01538506243377924\n",
            "accuracy in 432 epoch is 1.0\n",
            "\n",
            "Loss in 433 epoch is 0.015317370183765888\n",
            "accuracy in 433 epoch is 1.0\n",
            "\n",
            "Loss in 434 epoch is 0.015250167809426785\n",
            "accuracy in 434 epoch is 1.0\n",
            "\n",
            "Loss in 435 epoch is 0.015183448791503906\n",
            "accuracy in 435 epoch is 1.0\n",
            "\n",
            "Loss in 436 epoch is 0.01511720847338438\n",
            "accuracy in 436 epoch is 1.0\n",
            "\n",
            "Loss in 437 epoch is 0.015051450580358505\n",
            "accuracy in 437 epoch is 1.0\n",
            "\n",
            "Loss in 438 epoch is 0.014986160211265087\n",
            "accuracy in 438 epoch is 1.0\n",
            "\n",
            "Loss in 439 epoch is 0.014921336434781551\n",
            "accuracy in 439 epoch is 1.0\n",
            "\n",
            "Loss in 440 epoch is 0.0148569755256176\n",
            "accuracy in 440 epoch is 1.0\n",
            "\n",
            "Loss in 441 epoch is 0.01479308120906353\n",
            "accuracy in 441 epoch is 1.0\n",
            "\n",
            "Loss in 442 epoch is 0.014729629270732403\n",
            "accuracy in 442 epoch is 1.0\n",
            "\n",
            "Loss in 443 epoch is 0.014666642993688583\n",
            "accuracy in 443 epoch is 1.0\n",
            "\n",
            "Loss in 444 epoch is 0.014604093506932259\n",
            "accuracy in 444 epoch is 1.0\n",
            "\n",
            "Loss in 445 epoch is 0.014541983604431152\n",
            "accuracy in 445 epoch is 1.0\n",
            "\n",
            "Loss in 446 epoch is 0.014480316080152988\n",
            "accuracy in 446 epoch is 1.0\n",
            "\n",
            "Loss in 447 epoch is 0.014419076964259148\n",
            "accuracy in 447 epoch is 1.0\n",
            "\n",
            "Loss in 448 epoch is 0.014358272776007652\n",
            "accuracy in 448 epoch is 1.0\n",
            "\n",
            "Loss in 449 epoch is 0.014297893270850182\n",
            "accuracy in 449 epoch is 1.0\n",
            "\n",
            "Loss in 450 epoch is 0.014237937517464161\n",
            "accuracy in 450 epoch is 1.0\n",
            "\n",
            "Loss in 451 epoch is 0.014178404584527016\n",
            "accuracy in 451 epoch is 1.0\n",
            "\n",
            "Loss in 452 epoch is 0.014119274914264679\n",
            "accuracy in 452 epoch is 1.0\n",
            "\n",
            "Loss in 453 epoch is 0.014060558751225471\n",
            "accuracy in 453 epoch is 1.0\n",
            "\n",
            "Loss in 454 epoch is 0.01400225330144167\n",
            "accuracy in 454 epoch is 1.0\n",
            "\n",
            "Loss in 455 epoch is 0.013944351114332676\n",
            "accuracy in 455 epoch is 1.0\n",
            "\n",
            "Loss in 456 epoch is 0.013886840082705021\n",
            "accuracy in 456 epoch is 1.0\n",
            "\n",
            "Loss in 457 epoch is 0.013829732313752174\n",
            "accuracy in 457 epoch is 1.0\n",
            "\n",
            "Loss in 458 epoch is 0.013773011974990368\n",
            "accuracy in 458 epoch is 1.0\n",
            "\n",
            "Loss in 459 epoch is 0.013716679066419601\n",
            "accuracy in 459 epoch is 1.0\n",
            "\n",
            "Loss in 460 epoch is 0.013660735450685024\n",
            "accuracy in 460 epoch is 1.0\n",
            "\n",
            "Loss in 461 epoch is 0.013605175539851189\n",
            "accuracy in 461 epoch is 1.0\n",
            "\n",
            "Loss in 462 epoch is 0.013549992814660072\n",
            "accuracy in 462 epoch is 1.0\n",
            "\n",
            "Loss in 463 epoch is 0.01349517609924078\n",
            "accuracy in 463 epoch is 1.0\n",
            "\n",
            "Loss in 464 epoch is 0.013440734706819057\n",
            "accuracy in 464 epoch is 1.0\n",
            "\n",
            "Loss in 465 epoch is 0.013386664912104607\n",
            "accuracy in 465 epoch is 1.0\n",
            "\n",
            "Loss in 466 epoch is 0.013332956470549107\n",
            "accuracy in 466 epoch is 1.0\n",
            "\n",
            "Loss in 467 epoch is 0.013279609382152557\n",
            "accuracy in 467 epoch is 1.0\n",
            "\n",
            "Loss in 468 epoch is 0.01322660967707634\n",
            "accuracy in 468 epoch is 1.0\n",
            "\n",
            "Loss in 469 epoch is 0.013173983432352543\n",
            "accuracy in 469 epoch is 1.0\n",
            "\n",
            "Loss in 470 epoch is 0.01312170084565878\n",
            "accuracy in 470 epoch is 1.0\n",
            "\n",
            "Loss in 471 epoch is 0.013069763779640198\n",
            "accuracy in 471 epoch is 1.0\n",
            "\n",
            "Loss in 472 epoch is 0.013018175959587097\n",
            "accuracy in 472 epoch is 1.0\n",
            "\n",
            "Loss in 473 epoch is 0.012966930866241455\n",
            "accuracy in 473 epoch is 1.0\n",
            "\n",
            "Loss in 474 epoch is 0.012916023842990398\n",
            "accuracy in 474 epoch is 1.0\n",
            "\n",
            "Loss in 475 epoch is 0.012865455821156502\n",
            "accuracy in 475 epoch is 1.0\n",
            "\n",
            "Loss in 476 epoch is 0.012815217487514019\n",
            "accuracy in 476 epoch is 1.0\n",
            "\n",
            "Loss in 477 epoch is 0.012765305116772652\n",
            "accuracy in 477 epoch is 1.0\n",
            "\n",
            "Loss in 478 epoch is 0.012715722434222698\n",
            "accuracy in 478 epoch is 1.0\n",
            "\n",
            "Loss in 479 epoch is 0.012666474096477032\n",
            "accuracy in 479 epoch is 1.0\n",
            "\n",
            "Loss in 480 epoch is 0.012617538683116436\n",
            "accuracy in 480 epoch is 1.0\n",
            "\n",
            "Loss in 481 epoch is 0.012568922713398933\n",
            "accuracy in 481 epoch is 1.0\n",
            "\n",
            "Loss in 482 epoch is 0.01252062153071165\n",
            "accuracy in 482 epoch is 1.0\n",
            "\n",
            "Loss in 483 epoch is 0.012472638860344887\n",
            "accuracy in 483 epoch is 1.0\n",
            "\n",
            "Loss in 484 epoch is 0.012424962595105171\n",
            "accuracy in 484 epoch is 1.0\n",
            "\n",
            "Loss in 485 epoch is 0.012377594597637653\n",
            "accuracy in 485 epoch is 1.0\n",
            "\n",
            "Loss in 486 epoch is 0.012330536730587482\n",
            "accuracy in 486 epoch is 1.0\n",
            "\n",
            "Loss in 487 epoch is 0.012283779680728912\n",
            "accuracy in 487 epoch is 1.0\n",
            "\n",
            "Loss in 488 epoch is 0.01223731692880392\n",
            "accuracy in 488 epoch is 1.0\n",
            "\n",
            "Loss in 489 epoch is 0.012191154062747955\n",
            "accuracy in 489 epoch is 1.0\n",
            "\n",
            "Loss in 490 epoch is 0.012145289219915867\n",
            "accuracy in 490 epoch is 1.0\n",
            "\n",
            "Loss in 491 epoch is 0.01209971122443676\n",
            "accuracy in 491 epoch is 1.0\n",
            "\n",
            "Loss in 492 epoch is 0.012054426595568657\n",
            "accuracy in 492 epoch is 1.0\n",
            "\n",
            "Loss in 493 epoch is 0.01200942788273096\n",
            "accuracy in 493 epoch is 1.0\n",
            "\n",
            "Loss in 494 epoch is 0.011964721605181694\n",
            "accuracy in 494 epoch is 1.0\n",
            "\n",
            "Loss in 495 epoch is 0.01192028820514679\n",
            "accuracy in 495 epoch is 1.0\n",
            "\n",
            "Loss in 496 epoch is 0.011876139789819717\n",
            "accuracy in 496 epoch is 1.0\n",
            "\n",
            "Loss in 497 epoch is 0.011832263320684433\n",
            "accuracy in 497 epoch is 1.0\n",
            "\n",
            "Loss in 498 epoch is 0.011788667179644108\n",
            "accuracy in 498 epoch is 1.0\n",
            "\n",
            "Loss in 499 epoch is 0.011745347641408443\n",
            "accuracy in 499 epoch is 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2PSXnTDiNi"
      },
      "source": [
        "## Visualize the final node embeddings\n",
        "Visualize your final embedding here! \n",
        "You can visually compare the figure with the previous embedding figure. \n",
        "After training, you should oberserve that the two classes are more evidently separated. \n",
        "This is a great sanitity check for your implementation as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtNgl4VhYKow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1ec74b16-5d44-4e60-e5f3-89bdfe3c6485"
      },
      "source": [
        "# Visualize the final learned embedding\n",
        "visualize_emb(emb)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAFlCAYAAAD292MqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXQklEQVR4nO3dfWxc1ZnH8d/jxMg4L4oIlraLsSdi06opL2YzgrbZVhSKlKZR0iIikU6ihnTrZdm2aReEoP6nVDLa7laFor6wpoTSZpRuaUupCogNgghQ2pRJCVHeSqG1vUatcBNVNHUhOH72jztx7MnYM/bcmTtn/P1IljPX1+c+Y/AvJ+eec665uwAA4WpKugAAQGUIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwM1P4qLnn3++p1KpJC4NAMHat2/fn9y9rfB4IkGeSqWUy+WSuDQABMvMBoodZ2gFAAJHkANA4AhyAAhcImPkxbz99tsaGhrSm2++mXQpdaOlpUXt7e1qbm5OuhQAdSy2IDezeZJykl5z97Uz/f6hoSEtWrRIqVRKZhZXWcFydx07dkxDQ0NatmxZ0uUAqGNxDq1sk3Rktt/85ptvaunSpYR4nplp6dKl/AsFQEmxBLmZtUv6qKTvVNhOHOU0DH4eAMoRV4/8Hkm3SRqb6gQz6zaznJnlhoeHY7psvMxMmzZtGn89OjqqtrY2rV07s5Giq666atI8+f7+fl188cWSpFwup8997nPxFAwAiiHIzWytpNfdfd9057l7n7un3T3d1nbWwqS6sGDBAh08eFB/+9vfJEm7du3SBRdcUPTc0dHRWV0jnU7r3nvvnXWNAFAojh75KknrzKxf0g8kXW1mO2Jod3rZrJRKSU1N0edsNpZm16xZo8cee0yStHPnTm3cuHH8a1/60pe0efNmrVq1Sps3b55V+7t3755xDx9A/atSJJWl4lkr7n6HpDskycyuknSru2+a7nsqls1K3d3SyEj0emAgei1JmUxFTd9www368pe/rLVr1+rAgQPaunWrnnvuufGvHz58WM8//7zOPffcadvJZDLj55w8eVJNTUzZBxpVFSOpLGGmS0/PmZ/YaSMj0fEKXXrpperv79fOnTu1Zs2as76+bt26kiEuSdlsVvv379f+/fv1+OOPV1wXgPpVxUgqS6wLgtx9t6TdcbZZ1ODgzI7P0Lp163Trrbdq9+7dOnbs2KSvLViwIJZrAGgcVY6kkupmZeeMdHRE/3YpdjwGW7du1ZIlS3TJJZdo9+7dsbQJoHFVOZJKCnNopbdXam2dfKy1NToeg/b29rKmCHZ1dcVyPQBhq3IklebuNf9YuXKlFzp8+PBZx6a1Y4d7Z6e7WfR5x46ZfX8gZvxzAZCIWkSSpJwXydQwh1ak6FZwLW4HA0AZkoykMIdWAADjCHIACBxBDgCBI8gBIHAEOQAEjiCfYGhoSOvXr9fy5ct10UUXadu2bTp58qQkaePGjbr00kt199136+jRo+rq6tLll1+uV199Ve9///sTrhzAXEaQ57m7rrvuOn3sYx/Tb3/7W7388ss6ceKEenp69Mc//lEvvPCCDhw4oC984Qv66U9/quuvv14vvviiLrroIu3Zs6fi6892W1wACDbI494y8umnn1ZLS4tuvPFGSdK8efN09913a/v27frgBz+o1157TV1dXbrzzjt1zz336Nvf/rY+9KEPSZIWLlw43s5XvvIVXXLJJbrssst0++23S5JeffVVrV69WitXrtQHPvABHT16VJK0ZcsW3XTTTbryyit12223VfYGAMxZQS4IqsaWkYcOHdLKlSsnHVu8eLE6Ojr00EMP6ROf+IT2798vKeq9L1y4ULfeeuuk85944gk9+uij2rt3r1pbW3X8+HFJUnd3t+677z4tX75ce/fu1c0336ynn35aUjScs2fPHs2bN292hQOY84IM8um2jExysedTTz2lG2+8Ua35TRfOO+88nThxQnv27NGGDRvGz3vrrbfG/7xhwwZCHEBFggzyamwZuWLFCv3oRz+adOyNN97Q4OCg5s+f/Y9pbGxMS5YsGe/NF2JbXACVCnKMfKqtISvZMvKaa67RyMiIvve970mSTp06pVtuuUVbtmwZ72GXcu211+rBBx/USP6fC8ePH9fixYu1bNkyPfzww5KiYZmXXnpp9oUCQIEgg7waW0aamR555BE9/PDDWr58ud75zneqpaVFd911V9ltrF69WuvWrVM6nVZXV5e++tWvSoqeFvTAAw/osssu03ve8x49+uijsy8UAApYtDNibaXTac/lcpOOHTlyRO9+97vLbiObjcbEBwejnnhvb2NuhjjTnwuAxmVm+9w9XXg8yDFyiV1sAeC0IIdWAABnEOQAELi6CvIkxuvrGT8PAOWomyBvaWnRsWPHCK88d9exY8fU0tKSdCkA6lzd3Oxsb2/X0NCQhoeHky6lbrS0tKi9vT3pMgDUuboJ8ubmZi1btizpMgAgOHUztAIAmB2CHAACR5ADQOAIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwBHkABA4ghwAAkeQA0DgCHIACBxBDgCBI8gBIHAEOQAEjiAHgMBVHORm1mJmvzKzl8zskJndGUdhAIDyxPGEoLckXe3uJ8ysWdLzZvaEu/8yhrYBACVUHOQePS35RP5lc/6DJygDQI3EMkZuZvPMbL+k1yXtcve9Rc7pNrOcmeV4wDIAxCeWIHf3U+7eJald0hVmdnGRc/rcPe3u6ba2tjguCwBQzLNW3P3Pkp6RtDrOdgEAU4tj1kqbmS3J//lcSddKOlppuwCA8sQxa+Udkh4ys3mK/mL4obv/PIZ2AQBliGPWygFJl8dQCwBgFljZCQCBI8gBIHAEOQAEjiAHgMAR5AAQOIIcAAJHkANA4AhyAAgcQQ4AgSPIASBwBDkABI4gB4DAEeQAEDiCHAACR5ADQOAIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwBHkABA4ghwAAkeQA0DgCHIACBxBDgCBI8gBIHAEOQAEjiAHgMAR5AAQOIIcAAJHkANA4AhyAAgcQQ4AgSPIASBwBDkABI4gB4DAEeQAEDiCHAACR5ADQOAIcgAIXMVBbmYXmtkzZnbYzA6Z2bY4CgMAlGd+DG2MSrrF3X9tZosk7TOzXe5+OIa2AQAlVNwjd/c/uPuv83/+i6Qjki6otF0AQHliHSM3s5SkyyXtjbNdAMDUYgtyM1so6ceSPu/ubxT5ereZ5cwsNzw8HNdlAWDOiyXIzaxZUYhn3f0nxc5x9z53T7t7uq2tLY7LAgAUz6wVk/SApCPu/rXKSwIAzEQcPfJVkjZLutrM9uc/1sTQLgCgDBVPP3T35yVZDLUAAGaBlZ0AEDiCHAACR5ADQOAIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwBHkochmpVRKamqKPmezSVcEoE7E8WAJVFs2K3V3SyMj0euBgei1JGUyydUFoC7QIw9BT8+ZED9tZCQ6DmDOI8hDMDg4s+MA5hSCPAQdHTM7DmBOIchD0NsrtbZOPtbaGh0HMOcR5CHIZKS+PqmzUzKLPvf1caMTgCRmrYQjkyG4ARRFjxwAAkeQA0DgCHIACBxBDgCBI8gBIHAEOQAEjiAHgMAR5AAQOIIcAAJHkANA4AhyAAgcQQ4AgSPIASBwBDkABI4gB4DAEeQAEDiCHAACR5ADQOAIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwBHkABA4ghwAAhdLkJvZdjN73cwOxtEeAKB8cfXIvytpdUxtAQBmIJYgd/dnJR2Poy0AwMwwRg4AgatZkJtZt5nlzCw3PDxcq8sCQMOrWZC7e5+7p9093dbWVqvLAkDDY2gFAAIX1/TDnZJ+IeldZjZkZp+Ko10AQGnz42jE3TfG0Q4AYOYYWgGAwBHkABA4ghwAAkeQA0DgCHIACBxBDgCBI8gBIHAEOQAEjiAHgMAR5AAQOIIcAAJHkANA4AhyAAgcQQ4AgSPIASBwBDkABI4gB4DAEeQAEDiCHAACR5ADQOAIcgAIHEEOAIFrrCDPZqVUSmpqij5ns0lXBABVNz/pAmKTzUrd3dLISPR6YCB6LUmZTHJ1AUCVNU6PvKfnTIifNjISHQeABtY4QT44OLPjANAgGifIOzpmdhwAGkTjBHlvr9TaOulQtnmLUicOcu8TQENrnCDPZKS+PqmzUzJTduln1W33a+DYQrmfufdJmANoNObuNb9oOp32XC5X1WukUlF4F+rslPr7q3ppAKgKM9vn7unC443TIy8w1T3OgQGmmgNoLA0b5NPd4xwY0Phwy+bN0s03164uAIhbwwZ5b6/U3Fz6PHfpvvvomQMIV8MGeSYjLV5c3rnurBsCEK6GDXJJOn68/HNZNwQgVI0V5AWbZnWcd6Lsb510LptvAQhI4wT56U2zJtzJ7H3js2o9Z3TSafP0tqTJUy5b9Vf16otntZP1G5Qa2K2mTRuVWnSMPAdQlxonyLdtO2vTrMzb31Xfon+P1gjJ1al+PaRPaocy6lS/TGPqVL/69Glljn8j+qaeHmVH1ut8va5NympAKbmaNHBiqbq3jhLmAOpOYywIymalTZuKf81MGhubeoXQafmVQlnLqFt9GtGC6U4DgJoLfkHQtMPW0005OT2hfLq7mWbSmjVRU03/MWWIl2oGAJIQxIMlSj4zYrp07e2NPnd0TN0jd5ceekiSNDj2jWlrYTNFAPUmlh65ma02s9+Y2StmdnscbU5U8pkRU6Xr0qVnng40YXfErDYqpd+rSaeU0u+V1caowb4+dWjqvxRazxkd/3sBAOpFxUFuZvMkfVPSRyStkLTRzFZU2u5EJZ8ZUWQLW7W2Sl//+pnX+d0Rs0s/q27df+YmplLq1v1RmJ86pV59Ua36a8GVXEsXvKm+7fN5ahyAuhNHj/wKSa+4++/c/aSkH0haH0O740o+M6JgC1t1dkavC1M3k1HPwnvPGgMf0QL16K7oFO1Unz49aVbLDm3Sn/77x4Q4gLpU8awVM7te0mp3/+f8682SrnT3zxSc1y2pW5I6OjpWDkw3g6RA4Ri5FHW4i2V1KU1N0ZD4We9DYxrTvKm/kekqABKW+KwVd+9z97S7p9va2mb0veV2uMsxZe9+mrFxSUxXQcVYMIxqiSPIX5N04YTX7fljscpkog7x2Fj0uWiIl/GbUnQ4feLKzqkwXQUVKLLwmCdWITZxBPkLkpab2TIzO0fSDZJ+FkO7M1Pmb8qk3r1cnTYYrezUzuiE5mbpnHMmt93aKqaroBIlZ14BFag4yN19VNJnJD0p6YikH7r7oUrbnbEZ/KaM9+7d1P/955Tp3HNmzObBB6Xt2+MZxwHySs68AioQy4Igd39c0uNxtDVr5f6mZLNRuA8ORsMlvb3Fb2IS3IjRVOvRGLFDHIJZol9SyTmKYqASiZlqqQMjdohD4wR5Ob8pDFQiIXHOvAIKNcbuh6cVGzaZ+Jsy5STy/A6JAFDHpppHHsSmWWXLZKbv4jBQCaABNc7QSjnqbKCSBSIA4jC3gnwWA5XVClvuuwKIS2ONkcclP9aeHVilbrtfI36mFz/bPV4KTfXAIrZ0ATCVxPdaCcaErnKPeieFuJSf5PLJoYq7ziwQARAXgrzQhCmKgyp+E3Tw1N9L3d3K3vz8rIddypn2DgDlIMgLTegST7UjYocGlR1Zr+77/nHWY9x1dt8VQMAI8kITusTFnhZ0eqfEHt1VfNilzLVFLBABEBeCvNCErnKxpwWd3ilxymGXGYxxl7U1LwCUQJAXKugqZzr3qP9f/1NjrYvUr2Xj29122FDRb2eMG0CtEeTFFHaVv/Wts8ZBem8aZIwbQF0gyMtVEO6Zb/0TY9wA6kJj7bVSY6W2dgGAWqBHDgCBI8gBIHAEOQAEjiAHgMAR5AAQOIIcAAJHkANA4AhyAAgcQQ4AgSPIASBwBDkABI4gz8tmNevHtgFAktg0S2eet5x/VOf4Y9skNsUCUP/okWvS85bHzeSxbQCQJIJcUz+ebSaPbQOApBDkmvrxbDy2DUAICHJNet7yOB7bBiAUBLnOet4yj20DEBRmreTx2DYAoaJHDgCBI8gBIHAEOQAEjiAHgMAR5AAQOIIcAAJXUZCb2QYzO2RmY2aWjqsoAED5Ku2RH5R0naRnY6gFADALFS0IcvcjkmRm8VQDAJixmo2Rm1m3meXMLDc8PFyrywJAwyvZIzezpyT9XZEv9bj7o+VeyN37JPVJUjqd9rIrBABMq2SQu/uHa1EIAGB2mH4IAIGrdPrhx81sSNL7JD1mZk/GUxYAoFyVzlp5RNIjMdUCAJgFhlYAIHAEOQAEjiAHgMAR5AAQOIIcAAJHkANA4AhyAAgcQQ4AgSPIASBwBDkABI4gB4DAEeQAEDiCHAACR5ADQOAIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwBHkAFAD2ayUSklNTdHnbDa+tit6+DIAoLRsVurulkZGotcDA9FrScpkKm+fHjkAVFlPz5kQP21kJDoeB4IcAKpscHBmx2eKIAeAKuvomNnxmSLIAaDKenul1tbJx1pbo+NxIMgBoMoyGamvT+rslMyiz3198dzolJi1AgA1kcnEF9yF6JEDQOAIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwBHkABA4ghwAAkeQA0DgCHJUVTU30wcQYYk+qqbam+kDiNAjR9VUezN9ABGCHFVT7c30AUQqCnIz+y8zO2pmB8zsETNbElNdaADV3kwfQKTSHvkuSRe7+6WSXpZ0R+UloVFUezN9AJGKgtzd/9fdR/MvfympvfKS0CiqvZk+gEics1a2SvqfGNtDA6jmZvoAIiV75Gb2lJkdLPKxfsI5PZJGJU05S9jMus0sZ2a54eHheKoHMOewNuFs5u6VNWC2RdK/SLrG3UdKnC5JSqfTnsvlKrougLmncG2CFN13mStDdma2z93ThccrnbWyWtJtktaVG+IAMFusTSiu0lkr35C0SNIuM9tvZvfFUBMAFMXahOIqutnp7v8QVyEAUEpHR7TVQ7HjcxkrOwEEg7UJxRHkAILB2oTi2P0QQFBYm3A2euQAEDiCHAACR5ADQOAIcgAIHEEOAIEjyAEgcAQ5AASOIAeAwBHkABA4ghwAAlfxgyVmdVGzYUlF9jAbd76kP9WonHrA+21svN/GVsv32+nubYUHEwnyUswsV+wpGI2K99vYeL+NrR7eL0MrABA4ghwAAlevQd6XdAE1xvttbLzfxpb4+63LMXIAQPnqtUcOAChT3Qa5mW0ws0NmNmZmDXsH3MxWm9lvzOwVM7s96Xqqycy2m9nrZnYw6VpqwcwuNLNnzOxw/v/lbUnXVE1m1mJmvzKzl/Lv986ka6oFM5tnZi+a2c+TqqFug1zSQUnXSXo26UKqxczmSfqmpI9IWiFpo5mtSLaqqvqupNVJF1FDo5JucfcVkt4r6d8a/L/vW5KudvfLJHVJWm1m7022pJrYJulIkgXUbZC7+xF3/03SdVTZFZJecfffuftJST+QtD7hmqrG3Z+VdDzpOmrF3f/g7r/O//kvin7ZL0i2qurxyIn8y+b8R0PfhDOzdkkflfSdJOuo2yCfIy6Q9H8TXg+pgX/R5zIzS0m6XNLehEupqvwww35Jr0va5e4N/X4l3SPpNkljSRaRaJCb2VNmdrDIR8P2SjH3mNlCST+W9Hl3fyPpeqrJ3U+5e5ekdklXmNnFCZdUNWa2VtLr7r4v6VrmJ3lxd/9wktevA69JunDC6/b8MTQIM2tWFOJZd/9J0vXUirv/2cyeUXRPpFFvbq+StM7M1khqkbTYzHa4+6ZaF8LQSrJekLTczJaZ2TmSbpD0s4RrQkzMzCQ9IOmIu38t6XqqzczazGxJ/s/nSrpW0tFEi6oid7/D3dvdPaXod/fpJEJcquMgN7OPm9mQpPdJeszMnky6pri5+6ikz0h6UtGNsB+6+6Fkq6oeM9sp6ReS3mVmQ2b2qaRrqrJVkjZLutrM9uc/1iRdVBW9Q9IzZnZAUSdll7snNiVvLmFlJwAErm575ACA8hDkABA4ghwAAkeQA0DgCHIACBxBDgCBI8gBIHAEOQAE7v8BZv9Z4mfJ8zQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTNyrAoSVeq9"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_E7J_GkVhY_"
      },
      "source": [
        "In order to get credit, you must go submit your answers on Gradescope."
      ]
    }
  ]
}